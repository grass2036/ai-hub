"""
ç”Ÿäº§ç¯å¢ƒå°±ç»ªæµ‹è¯•
Week 6 Day 6: ç”Ÿäº§ç¯å¢ƒæœ€ç»ˆéªŒè¯

éªŒè¯AI Hubå¹³å°æ˜¯å¦å‡†å¤‡å¥½æŠ•å…¥ç”Ÿäº§ç¯å¢ƒ
"""

import asyncio
import pytest
import time
import requests
import subprocess
import docker
from datetime import datetime
from typing import Dict, List, Any
import psutil
import json
import os


class TestProductionReadiness:
    """ç”Ÿäº§ç¯å¢ƒå°±ç»ªæµ‹è¯•å¥—ä»¶"""

    @pytest.fixture(scope="class")
    def docker_client(self):
        """Dockerå®¢æˆ·ç«¯"""
        return docker.from_env()

    @pytest.fixture(scope="class")
    def test_config(self):
        """æµ‹è¯•é…ç½®"""
        return {
            "base_url": "http://localhost",
            "ha_url": "http://localhost/api/v1/ha",
            "backup_url": "http://localhost/api/v1/backup",
            "monitoring_url": "http://localhost:9091",
            "grafana_url": "http://localhost:3001",
            "timeout": 30,
            "max_retries": 3
        }

    @pytest.fixture(autouse=True)
    def setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸‹
        os.chdir("/Users/chiyingjie/code/git/ai-hub")

        # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶
        required_files = [
            "docker-compose.ha.yml",
            "docker-compose.backup.yml",
            "docker-compose.monitoring.yml"
        ]

        for file in required_files:
            if not os.path.exists(file):
                pytest.skip(f"Required file not found: {file}")

    class TestDockerDeployment:
        """Dockeréƒ¨ç½²æµ‹è¯•"""

        @pytest.mark.asyncio
        async def test_docker_services_running(self, docker_client):
            """æµ‹è¯•DockeræœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ"""
            running_services = []

            # æ£€æŸ¥ä¸»è¦æœåŠ¡
            expected_services = [
                "ai-hub-app-1",
                "ai-hub-app-2",
                "ai-hub-app-3",
                "ai-hub-nginx",
                "ai-hub-postgres-backup",
                "ai-hub-redis-backup",
                "ai-hub-backup-storage"
            ]

            for service_name in expected_services:
                try:
                    containers = docker_client.containers.list(
                        filters={"name": service_name, "status": "running"}
                    )
                    if containers:
                        running_services.append(service_name)
                        print(f"âœ“ Service {service_name} is running")
                    else:
                        print(f"âœ— Service {service_name} is not running")
                except Exception as e:
                    print(f"âœ— Error checking service {service_name}: {str(e)}")

            # è‡³å°‘70%çš„æœåŠ¡åº”è¯¥è¿è¡Œ
            min_services = len(expected_services) * 0.7
            assert len(running_services) >= min_services, \
                f"Only {len(running_services)}/{len(expected_services)} services are running"

        @pytest.mark.asyncio
        async def test_container_health_checks(self, docker_client):
            """æµ‹è¯•å®¹å™¨å¥åº·æ£€æŸ¥"""
            unhealthy_containers = []

            containers = docker_client.containers.list(filters={"status": "running"})

            for container in containers:
                try:
                    health = container.attrs.get("State", {}).get("Health", {})
                    if health:
                        status = health.get("Status", "unknown")
                        if status != "healthy":
                            unhealthy_containers.append({
                                "name": container.name,
                                "status": status
                            })
                            print(f"âœ— Container {container.name} is {status}")
                        else:
                            print(f"âœ“ Container {container.name} is healthy")
                    else:
                        print(f"! Container {container.name} has no health check")
                except Exception as e:
                    print(f"âœ— Error checking container health: {str(e)}")

            # ä¸è¶…è¿‡30%çš„å®¹å™¨åº”è¯¥ä¸å¥åº·
            total_containers = len(containers)
            max_unhealthy = total_containers * 0.3 if total_containers > 0 else 0

            assert len(unhealthy_containers) <= max_unhealthy, \
                f"Too many unhealthy containers: {len(unhealthy_containers)}"

        @pytest.mark.asyncio
        async def test_network_connectivity(self):
            """æµ‹è¯•ç½‘ç»œè¿é€šæ€§"""
            network_name = "ai-hub-ha_backup-network"

            try:
                # æ£€æŸ¥ç½‘ç»œæ˜¯å¦å­˜åœ¨
                result = subprocess.run(
                    ["docker", "network", "ls", "--filter", f"name={network_name}"],
                    capture_output=True, text=True
                )

                if network_name in result.stdout:
                    print(f"âœ“ Network {network_name} exists")
                else:
                    pytest.fail(f"Network {network_name} not found")

            except Exception as e:
                pytest.fail(f"Error checking network: {str(e)}")

        @pytest.mark.asyncio
        async def test_volume_mounts(self, docker_client):
            """æµ‹è¯•æ•°æ®å·æŒ‚è½½"""
            mounted_volumes = []

            containers = docker_client.containers.list(filters={"status": "running"})

            for container in containers:
                try:
                    mounts = container.attrs.get("Mounts", [])
                    if mounts:
                        for mount in mounts:
                            if mount.get("Type") == "volume":
                                mounted_volumes.append({
                                    "container": container.name,
                                    "volume": mount.get("Name"),
                                    "destination": mount.get("Destination")
                                })
                except Exception as e:
                    print(f"Error checking container {container.name} mounts: {str(e)}")

            # åº”è¯¥æœ‰æ•°æ®å·æŒ‚è½½
            assert len(mounted_volumes) > 0, "No volume mounts found"
            print(f"âœ“ Found {len(mounted_volumes)} volume mounts")

    class TestAPIEndpoints:
        """APIç«¯ç‚¹æµ‹è¯•"""

        @pytest.mark.asyncio
        async def test_core_api_endpoints(self, test_config):
            """æµ‹è¯•æ ¸å¿ƒAPIç«¯ç‚¹"""
            endpoints = [
                "/api/v1/health",
                "/api/v1/status",
                "/api/v1/models"
            ]

            failed_endpoints = []

            for endpoint in endpoints:
                url = f"{test_config['base_url']}{endpoint}"

                for attempt in range(test_config["max_retries"]):
                    try:
                        response = requests.get(
                            url,
                            timeout=test_config["timeout"]
                        )

                        if response.status_code == 200:
                            print(f"âœ“ API endpoint {endpoint} is responding")
                            break
                        else:
                            print(f"âœ— API endpoint {endpoint} returned {response.status_code}")
                            failed_endpoints.append(endpoint)
                            break

                    except requests.exceptions.RequestException as e:
                        if attempt == test_config["max_retries"] - 1:
                            print(f"âœ— API endpoint {endpoint} is not accessible: {str(e)}")
                            failed_endpoints.append(endpoint)
                        else:
                            await asyncio.sleep(2)  # ç­‰å¾…åé‡è¯•

            # æ‰€æœ‰æ ¸å¿ƒç«¯ç‚¹éƒ½åº”è¯¥å“åº”
            assert len(failed_endpoints) == 0, \
                f"Failed API endpoints: {failed_endpoints}"

        @pytest.mark.asyncio
        async def test_high_availability_endpoints(self, test_config):
            """æµ‹è¯•é«˜å¯ç”¨APIç«¯ç‚¹"""
            ha_endpoints = [
                "/api/v1/ha/status",
                "/api/v1/ha/load-balancer/stats"
            ]

            for endpoint in ha_endpoints:
                url = f"{test_config['base_url']}{endpoint}"

                try:
                    response = requests.get(
                        url,
                        timeout=test_config["timeout"]
                    )

                    if response.status_code == 200:
                        data = response.json()
                        assert data.get("success", False), f"HA endpoint {endpoint} returned failure"
                        print(f"âœ“ HA endpoint {endpoint} is working")
                    else:
                        pytest.fail(f"HA endpoint {endpoint} returned {response.status_code}")

                except requests.exceptions.RequestException as e:
                    pytest.fail(f"HA endpoint {endpoint} not accessible: {str(e)}")

        @pytest.mark.asyncio
        async def test_backup_endpoints(self, test_config):
            """æµ‹è¯•å¤‡ä»½APIç«¯ç‚¹"""
            backup_endpoints = [
                "/api/v1/backup/health",
                "/api/v1/backup/statistics"
            ]

            for endpoint in backup_endpoints:
                url = f"{test_config['base_url']}{endpoint}"

                try:
                    response = requests.get(
                        url,
                        timeout=test_config["timeout"]
                    )

                    if response.status_code == 200:
                        print(f"âœ“ Backup endpoint {endpoint} is working")
                    else:
                        print(f"âš  Backup endpoint {endpoint} returned {response.status_code}")

                except requests.exceptions.RequestException as e:
                    print(f"âš  Backup endpoint {endpoint} not accessible: {str(e)}")

    class TestDatabaseConnections:
        """æ•°æ®åº“è¿æ¥æµ‹è¯•"""

        @pytest.mark.asyncio
        async def test_postgresql_connection(self, docker_client):
            """æµ‹è¯•PostgreSQLè¿æ¥"""
            try:
                # è·å–PostgreSQLå®¹å™¨
                postgres_container = docker_client.containers.get("ai-hub-postgres-backup")

                # æ‰§è¡Œè¿æ¥æµ‹è¯•
                exit_code, output = postgres_container.exec_run(
                    "pg_isready -U aihub"
                )

                if exit_code == 0:
                    print("âœ“ PostgreSQL connection is working")
                else:
                    pytest.fail(f"PostgreSQL connection failed: {output.decode()}")

            except docker.errors.NotFound:
                pytest.skip("PostgreSQL container not found")
            except Exception as e:
                pytest.fail(f"Error testing PostgreSQL connection: {str(e)}")

        @pytest.mark.asyncio
        async def test_redis_connection(self, docker_client):
            """æµ‹è¯•Redisè¿æ¥"""
            try:
                # è·å–Rediså®¹å™¨
                redis_container = docker_client.containers.get("ai-hub-redis-backup")

                # æ‰§è¡Œè¿æ¥æµ‹è¯•
                exit_code, output = redis_container.exec_run(
                    "redis-cli ping"
                )

                if exit_code == 0 and "PONG" in output.decode():
                    print("âœ“ Redis connection is working")
                else:
                    pytest.fail(f"Redis connection failed: {output.decode()}")

            except docker.errors.NotFound:
                pytest.skip("Redis container not found")
            except Exception as e:
                pytest.fail(f"Error testing Redis connection: {str(e)}")

    class TestMonitoringSystem:
        """ç›‘æ§ç³»ç»Ÿæµ‹è¯•"""

        @pytest.mark.asyncio
        async def test_prometheus_health(self, test_config):
            """æµ‹è¯•Prometheuså¥åº·çŠ¶æ€"""
            try:
                response = requests.get(
                    f"{test_config['monitoring_url']}/-/healthy",
                    timeout=10
                )

                if response.status_code == 200:
                    print("âœ“ Prometheus is healthy")
                else:
                    pytest.fail(f"Prometheus health check failed: {response.status_code}")

            except requests.exceptions.RequestException as e:
                pytest.skip(f"Prometheus not accessible: {str(e)}")

        @pytest.mark.asyncio
        async def test_grafana_health(self, test_config):
            """æµ‹è¯•Grafanaå¥åº·çŠ¶æ€"""
            try:
                response = requests.get(
                    f"{test_config['grafana_url']}/api/health",
                    timeout=10
                )

                if response.status_code == 200:
                    print("âœ“ Grafana is healthy")
                else:
                    print(f"âš  Grafana health check returned: {response.status_code}")

            except requests.exceptions.RequestException as e:
                pytest.skip(f"Grafana not accessible: {str(e)}")

        @pytest.mark.asyncio
        async def test_metrics_collection(self, test_config):
            """æµ‹è¯•æŒ‡æ ‡æ”¶é›†"""
            try:
                response = requests.get(
                    f"{test_config['monitoring_url']}/api/v1/query?query=up",
                    timeout=10
                )

                if response.status_code == 200:
                    data = response.json()
                    if data.get("status") == "success":
                        metrics_count = len(data.get("data", {}).get("result", []))
                        if metrics_count > 0:
                            print(f"âœ“ Metrics collection working ({metrics_count} targets up)")
                        else:
                            pytest.fail("No metrics targets are up")
                    else:
                        pytest.fail("Metrics query failed")
                else:
                    pytest.fail(f"Metrics query failed: {response.status_code}")

            except requests.exceptions.RequestException as e:
                pytest.skip(f"Metrics collection test failed: {str(e)}")

    class TestSystemPerformance:
        """ç³»ç»Ÿæ€§èƒ½æµ‹è¯•"""

        @pytest.mark.asyncio
        async def test_api_response_time(self, test_config):
            """æµ‹è¯•APIå“åº”æ—¶é—´"""
            endpoint = f"{test_config['base_url']}/api/v1/health"

            response_times = []

            # æµ‹è¯•5æ¬¡å“åº”æ—¶é—´
            for i in range(5):
                try:
                    start_time = time.time()
                    response = requests.get(endpoint, timeout=10)
                    end_time = time.time()

                    if response.status_code == 200:
                        response_time = end_time - start_time
                        response_times.append(response_time)
                    else:
                        pytest.fail(f"API request failed with status {response.status_code}")

                except requests.exceptions.RequestException as e:
                    pytest.fail(f"API request failed: {str(e)}")

            # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
            avg_response_time = sum(response_times) / len(response_times)
            max_response_time = max(response_times)

            print(f"âœ“ Average response time: {avg_response_time:.3f}s")
            print(f"âœ“ Max response time: {max_response_time:.3f}s")

            # å“åº”æ—¶é—´åº”è¯¥å°äº2ç§’
            assert avg_response_time < 2.0, \
                f"Average response time too high: {avg_response_time:.3f}s"
            assert max_response_time < 5.0, \
                f"Max response time too high: {max_response_time:.3f}s"

        @pytest.mark.asyncio
        async def test_system_resources(self):
            """æµ‹è¯•ç³»ç»Ÿèµ„æºä½¿ç”¨"""
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            print(f"âœ“ CPU usage: {cpu_percent}%")

            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            print(f"âœ“ Memory usage: {memory.percent}%")

            # ç£ç›˜ä½¿ç”¨ç‡
            disk = psutil.disk_usage('/')
            disk_percent = (disk.used / disk.total) * 100
            print(f"âœ“ Disk usage: {disk_percent:.1f}%")

            # èµ„æºä½¿ç”¨åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
            assert cpu_percent < 80.0, f"CPU usage too high: {cpu_percent}%"
            assert memory.percent < 80.0, f"Memory usage too high: {memory.percent}%"
            assert disk_percent < 85.0, f"Disk usage too high: {disk_percent:.1f}%"

    class TestBackupSystem:
        """å¤‡ä»½ç³»ç»Ÿæµ‹è¯•"""

        @pytest.mark.asyncio
        async def test_backup_storage_health(self, docker_client):
            """æµ‹è¯•å¤‡ä»½å­˜å‚¨å¥åº·çŠ¶æ€"""
            try:
                # æ£€æŸ¥MinIOå­˜å‚¨å®¹å™¨
                storage_container = docker_client.containers.get("ai-hub-backup-storage")

                # æ£€æŸ¥å­˜å‚¨æœåŠ¡
                exit_code, output = storage_container.exec_run(
                    "curl -f http://localhost:9000/minio/health/live"
                )

                if exit_code == 0:
                    print("âœ“ MinIO storage is healthy")
                else:
                    pytest.fail(f"MinIO storage health check failed: {output.decode()}")

            except docker.errors.NotFound:
                pytest.skip("MinIO storage container not found")
            except Exception as e:
                pytest.fail(f"Error testing backup storage: {str(e)}")

        @pytest.mark.asyncio
        async def test_backup_configuration(self, test_config):
            """æµ‹è¯•å¤‡ä»½é…ç½®"""
            try:
                response = requests.get(
                    f"{test_config['backup_url']}/health",
                    timeout=10
                )

                if response.status_code == 200:
                    data = response.json()
                    components = data.get("components", {})

                    required_components = [
                        "backup_manager",
                        "recovery_manager",
                        "backup_scheduler",
                        "disaster_recovery"
                    ]

                    missing_components = []
                    for component in required_components:
                        if not components.get(component, False):
                            missing_components.append(component)

                    if missing_components:
                        print(f"âš  Missing backup components: {missing_components}")
                    else:
                        print("âœ“ All backup components are initialized")

                else:
                    pytest.fail(f"Backup health check failed: {response.status_code}")

            except requests.exceptions.RequestException as e:
                pytest.skip(f"Backup configuration test failed: {str(e)}")

    class TestSecurityConfiguration:
        """å®‰å…¨é…ç½®æµ‹è¯•"""

        @pytest.mark.asyncio
        async def test_ssl_configuration(self, test_config):
            """æµ‹è¯•SSLé…ç½®"""
            try:
                # å°è¯•HTTPSè¿æ¥
                response = requests.get(
                    f"https://localhost/api/v1/health",
                    verify=False,  # å¿½ç•¥è¯ä¹¦éªŒè¯
                    timeout=10
                )

                if response.status_code == 200:
                    print("âœ“ HTTPS is working")
                else:
                    print(f"âš  HTTPS returned status: {response.status_code}")

            except requests.exceptions.SSLError:
                print("âš  SSL certificate issues detected")
            except requests.exceptions.RequestException:
                print("âš  HTTPS not configured or accessible")

        @pytest.mark.asyncio
        async def test_api_security_headers(self, test_config):
            """æµ‹è¯•APIå®‰å…¨å¤´"""
            try:
                response = requests.get(
                    f"{test_config['base_url']}/api/v1/health",
                    timeout=10
                )

                headers = response.headers

                # æ£€æŸ¥å®‰å…¨ç›¸å…³çš„å¤´
                security_headers = [
                    "x-content-type-options",
                    "x-frame-options",
                    "x-xss-protection"
                ]

                missing_headers = []
                for header in security_headers:
                    if header not in headers:
                        missing_headers.append(header)

                if missing_headers:
                    print(f"âš  Missing security headers: {missing_headers}")
                else:
                    print("âœ“ Security headers are present")

            except requests.exceptions.RequestException as e:
                pytest.skip(f"Security headers test failed: {str(e)}")


# æµ‹è¯•è¿è¡Œå™¨
class TestRunner:
    """æµ‹è¯•è¿è¡Œå™¨"""

    @staticmethod
    async def run_production_readiness_tests():
        """è¿è¡Œç”Ÿäº§ç¯å¢ƒå°±ç»ªæµ‹è¯•"""
        print("å¼€å§‹AI Hubå¹³å°ç”Ÿäº§ç¯å¢ƒå°±ç»ªæµ‹è¯•...")
        print(f"æµ‹è¯•å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)

        # è¿è¡Œpytest
        import subprocess
        import sys

        test_command = [
            sys.executable, "-m", "pytest",
            __file__,
            "-v",
            "--tb=short",
            "--color=yes"
        ]

        result = subprocess.run(test_command, capture_output=True, text=True)

        print("=" * 60)
        print("æµ‹è¯•ç»“æœ:")
        print(result.stdout)

        if result.stderr:
            print("é”™è¯¯ä¿¡æ¯:")
            print(result.stderr)

        print(f"æµ‹è¯•ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        return result.returncode == 0


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    import asyncio

    success = asyncio.run(TestRunner.run_production_readiness_tests())

    if success:
        print("\nğŸŸ¢ ç”Ÿäº§ç¯å¢ƒå°±ç»ªæµ‹è¯•é€šè¿‡ï¼")
        exit(0)
    else:
        print("\nğŸ”´ ç”Ÿäº§ç¯å¢ƒå°±ç»ªæµ‹è¯•å¤±è´¥ï¼")
        exit(1)