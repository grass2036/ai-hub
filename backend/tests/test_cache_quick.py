"""
ç¼“å­˜ç³»ç»Ÿå¿«é€Ÿæµ‹è¯•è„šæœ¬
éªŒè¯ç¼“å­˜ç³»ç»Ÿï¿½ï¿½ï¿½æœ¬åŠŸèƒ½å’ŒAPIæ¥å£
"""

import asyncio
import json
import time
import logging
from typing import Dict, Any

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_cache_basic_functionality():
    """æµ‹è¯•ç¼“å­˜åŸºæœ¬åŠŸèƒ½"""
    logger.info("ğŸš€ Testing Cache System Basic Functionality...")

    try:
        # å¯¼å…¥ç¼“å­˜æ¨¡å—
        from backend.core.cache.multi_level_cache import (
            CacheConfig, MultiLevelCacheManager, get_cache_manager
        )
        from backend.core.cache.cache_warmup import (
            get_warmup_manager, WarmupPriority
        )
        from backend.core.cache.cache_monitor import (
            get_monitoring_system, record_cache_operation
        )

        # æµ‹è¯•ç¼“å­˜é…ç½®
        logger.info("ğŸ“Š Testing Cache Configuration...")
        config = CacheConfig(
            l1_max_size=100,
            l1_ttl=60,
            l2_host="localhost",
            l2_port=6379,
            l3_enabled=False  # ç®€åŒ–æµ‹è¯•
        )
        logger.info(f"âœ… Cache config created: L1 size={config.l1_max_size}")

        # æµ‹è¯•ç¼“å­˜ç®¡ç†å™¨
        logger.info("ğŸ’¾ Testing Cache Manager...")
        cache_manager = MultiLevelCacheManager(config)

        # æ¨¡æ‹ŸRedisè¿æ¥ï¼ˆé¿å…çœŸå®Redisä¾èµ–ï¼‰
        import unittest.mock
        with unittest.mock.patch('aioredis.Redis'):
            await cache_manager.initialize()
            logger.info("âœ… Cache manager initialized successfully")

        # æµ‹è¯•ç¼“å­˜æ“ä½œ
        test_key = "test_quick_key"
        test_value = {"message": "Hello Cache!", "timestamp": time.time()}

        # è®¾ç½®ç¼“å­˜
        await cache_manager.set(test_key, test_value, ttl=300)
        logger.info("âœ… Cache set operation successful")

        # è·å–ç¼“å­˜
        cached_value = await cache_manager.get(test_key)
        assert cached_value == test_value, f"Expected {test_value}, got {cached_value}"
        logger.info("âœ… Cache get operation successful")

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = await cache_manager.get_comprehensive_stats()
        logger.info(f"âœ… Cache stats retrieved: L1 hits={stats.get('overall', {}).get('l1_hits', 0)}")

        await cache_manager.close()

    except Exception as e:
        logger.error(f"âŒ Cache functionality test failed: {e}")
        return False

    return True


async def test_cache_warmup_system():
    """æµ‹è¯•ç¼“å­˜é¢„çƒ­ç³»ç»Ÿ"""
    logger.info("ğŸ”¥ Testing Cache Warmup System...")

    try:
        from backend.core.cache.cache_warmup import (
            get_warmup_manager, WarmupPriority, WarmupStrategy
        )

        warmup_manager = await get_warmup_manager()

        # æ¨¡æ‹Ÿé¢„çƒ­ä»»åŠ¡
        test_keys = ["warmup_test_1", "warmup_test_2", "warmup_test_3"]

        # å¼ºåˆ¶é¢„çƒ­
        scheduled_count = await warmup_manager.force_warmup(test_keys, WarmupPriority.MEDIUM)
        logger.info(f"âœ… Scheduled {scheduled_count} warmup tasks")

        # è·å–é¢„çƒ­ç»Ÿè®¡
        warmup_stats = await warmup_manager.get_warmup_stats()
        logger.info(f"âœ… Warmup stats: queue_size={warmup_stats.get('queue_size', 0)}")

    except Exception as e:
        logger.error(f"âŒ Cache warmup test failed: {e}")
        return False

    return True


async def test_cache_monitoring_system():
    """æµ‹è¯•ç¼“å­˜ç›‘æ§ç³»ç»Ÿ"""
    logger.info("ğŸ“ˆ Testing Cache Monitoring System...")

    try:
        from backend.core.cache.cache_monitor import (
            get_monitoring_system, MetricType
        )

        monitoring_system = await get_monitoring_system()

        # è®°å½•ä¸€äº›ç¼“å­˜æ“ä½œ
        await record_cache_operation("get", "l1_memory", 0.001, hit=True)
        await record_cache_operation("set", "l1_memory", 0.002, key_size=100)
        await record_cache_operation("get", "l2_redis", 0.005, hit=False)

        logger.info("âœ… Recorded cache operations for monitoring")

        # è·å–ç›‘æ§ä»ªè¡¨ç›˜
        dashboard = await monitoring_system.get_monitoring_dashboard()
        logger.info(f"âœ… Monitoring dashboard retrieved: score={dashboard.get('performance_score', 0)}")

    except Exception as e:
        logger.error(f"âŒ Cache monitoring test failed: {e}")
        return False

    return True


async def test_cache_api_endpoints():
    """æµ‹è¯•ç¼“å­˜APIç«¯ç‚¹"""
    logger.info("ğŸ”Œ Testing Cache API Endpoints...")

    try:
        from backend.api.v1.cache import router, CacheStatsResponse
        from fastapi import FastAPI

        # åˆ›å»ºæµ‹è¯•åº”ç”¨
        app = FastAPI()
        app.include_router(router, prefix="/api/v1")

        logger.info("âœ… Cache API router created successfully")

        # æµ‹è¯•APIå“åº”æ¨¡å‹
        test_response = CacheStatsResponse(
            success=True,
            message="Test successful",
            data={"test": "data"}
        )

        assert test_response.success == True
        assert test_response.data["test"] == "data"
        logger.info("âœ… Cache API response model working")

    except Exception as e:
        logger.error(f"âŒ Cache API test failed: {e}")
        return False

    return True


async def test_cache_middleware():
    """æµ‹è¯•ç¼“å­˜ä¸­é—´ä»¶"""
    logger.info("âš™ï¸ Testing Cache Middleware...")

    try:
        from backend.middleware.cache_middleware import (
            APICacheMiddleware, CacheRule, CacheStrategy, CacheKeyStrategy
        )

        # åˆ›å»ºæµ‹è¯•è§„åˆ™
        test_rules = [
            CacheRule(
                path_pattern="/test/api/*",
                methods=["GET"],
                cache_ttl=300,
                strategy=CacheStrategy.MULTI_LEVEL,
                key_strategy=CacheKeyStrategy.PATH_PARAMS
            )
        ]

        # åˆ›å»ºä¸­é—´ä»¶
        middleware = APICacheMiddleware(None, test_rules)

        # æµ‹è¯•è§„åˆ™åŒ¹é…
        from unittest.mock import Mock
        mock_request = Mock()
        mock_request.method = "GET"
        mock_request.url.path = "/test/api/users"
        mock_request.url = Mock()
        mock_request.url.path = "/test/api/users"
        mock_request.query_params = {}
        mock_request.headers = {}

        rule = middleware._find_matching_rule(mock_request)
        assert rule is not None, "Should find matching rule"
        logger.info("âœ… Cache middleware rule matching working")

        # æµ‹è¯•ç¼“å­˜é”®ç”Ÿæˆ
        cache_key = middleware._generate_cache_key(mock_request, rule)
        assert "api_cache" in cache_key, "Cache key should contain api_cache prefix"
        logger.info("âœ… Cache key generation working")

    except Exception as e:
        logger.error(f"âŒ Cache middleware test failed: {e}")
        return False

    return True


async def test_cache_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    logger.info("âš¡ Testing Cache Performance...")

    try:
        from backend.core.cache.multi_level_cache import CacheConfig, MultiLevelCacheManager
        import time

        config = CacheConfig(l1_max_size=1000, l3_enabled=False)
        manager = MultiLevelCacheManager(config)

        # æ¨¡æ‹ŸRedis
        import unittest.mock
        with unittest.mock.patch('aioredis.Redis'):
            await manager.initialize()

        # æ€§èƒ½æµ‹è¯•
        num_operations = 100
        test_data = {"performance": "test", "data": list(range(10))}

        # æµ‹è¯•å†™å…¥æ€§èƒ½
        start_time = time.time()
        for i in range(num_operations):
            await manager.set(f"perf_key_{i}", f"{test_data}_{i}")
        set_time = time.time() - start_time
        set_ops = num_operations / set_time

        # æµ‹è¯•è¯»å–æ€§èƒ½
        start_time = time.time()
        for i in range(num_operations):
            await manager.get(f"perf_key_{i}")
        get_time = time.time() - start_time
        get_ops = num_operations / get_time

        logger.info(f"âœ… Performance results:")
        logger.info(f"   Set: {set_ops:.0f} ops/sec ({set_time:.3f}s)")
        logger.info(f"   Get: {get_ops:.0f} ops/sec ({get_time:.3f}s)")

        # æ€§èƒ½è¦æ±‚æ£€æŸ¥
        assert set_ops > 100, f"Set performance too low: {set_ops:.0f} ops/sec"
        assert get_ops > 1000, f"Get performance too low: {get_ops:.0f} ops/sec"

        await manager.close()

    except Exception as e:
        logger.error(f"âŒ Cache performance test failed: {e}")
        return False

    return True


async def test_cache_integration():
    """æµ‹è¯•ç¼“å­˜ç³»ç»Ÿé›†æˆ"""
    logger.info("ğŸ”— Testing Cache System Integration...")

    try:
        from backend.core.cache.multi_level_cache import get_cache_manager
        from backend.core.cache.cache_warmup import get_warmup_manager
        from backend.core.cache.cache_monitor import get_monitoring_system

        # è·å–æ‰€æœ‰ç³»ç»Ÿç»„ä»¶
        cache_manager = await get_cache_manager()
        warmup_manager = await get_warmup_manager()
        monitoring_system = await get_monitoring_system()

        logger.info("âœ… All cache system components initialized")

        # æµ‹è¯•ç»„ä»¶é—´åä½œ
        test_key = "integration_test"
        test_value = {"integration": "test", "timestamp": time.time()}

        # é€šè¿‡ç¼“å­˜ç®¡ç†å™¨è®¾ç½®
        await cache_manager.set(test_key, test_value)

        # è®°å½•è®¿é—®åˆ°ç›‘æ§ç³»ç»Ÿ
        await monitoring_system.record_cache_operation(
            "get", "l1_memory", 0.001, hit=True
        )

        # è·å–ç¼“å­˜å€¼
        cached_value = await cache_manager.get(test_key)
        assert cached_value == test_value

        logger.info("âœ… Cache system integration working correctly")

    except Exception as e:
        logger.error(f"âŒ Cache integration test failed: {e}")
        return False

    return True


async def run_all_cache_tests():
    """è¿è¡Œæ‰€æœ‰ç¼“å­˜æµ‹è¯•"""
    logger.info("ğŸ¯ Starting Comprehensive Cache System Tests...")
    logger.info("=" * 60)

    test_functions = [
        ("Basic Functionality", test_cache_basic_functionality),
        ("Warmup System", test_cache_warmup_system),
        ("Monitoring System", test_cache_monitoring_system),
        ("API Endpoints", test_cache_api_endpoints),
        ("Cache Middleware", test_cache_middleware),
        ("Performance Test", test_cache_performance),
        ("Integration Test", test_cache_integration)
    ]

    passed = 0
    total = len(test_functions)

    for test_name, test_func in test_functions:
        logger.info(f"\nğŸ§ª Running {test_name} Test...")
        logger.info("-" * 40)

        try:
            result = await test_func()
            if result:
                logger.info(f"âœ… {test_name} Test PASSED")
                passed += 1
            else:
                logger.error(f"âŒ {test_name} Test FAILED")
        except Exception as e:
            logger.error(f"âŒ {test_name} Test ERROR: {e}")

        logger.info("-" * 40)

    # æ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info(f"ğŸ“Š Test Summary: {passed}/{total} tests passed")
    logger.info(f"ğŸ† Success Rate: {(passed/total)*100:.1f}%")

    if passed == total:
        logger.info("ğŸ‰ All cache system tests PASSED!")
        return True
    else:
        logger.error(f"ğŸ’¥ {total - passed} cache system tests FAILED!")
        return False


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ AI Hub Platform - Cache System Quick Test")
    print("=" * 60)

    try:
        success = await run_all_cache_tests()
        if success:
            print("\nğŸŠ Cache System is ready for production!")
            exit(0)
        else:
            print("\nâš ï¸  Cache System needs attention before production use.")
            exit(1)
    except KeyboardInterrupt:
        print("\nğŸ›‘ Test interrupted by user")
        exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ Test failed with error: {e}")
        exit(1)


if __name__ == "__main__":
    asyncio.run(main())