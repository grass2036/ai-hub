"""
å¹¶å‘æ€§èƒ½ä¼˜åŒ–æ¨¡å—
Week 6 Day 2: æ€§èƒ½ä¼˜åŒ–å’Œè°ƒä¼˜ - å¹¶å‘æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
å®ç°å¼‚æ­¥å¤„ç†ã€ä»»åŠ¡é˜Ÿåˆ—ã€èµ„æºæ± ç®¡ï¿½ï¿½ã€è´Ÿè½½å‡è¡¡ç­‰åŠŸèƒ½
"""

import asyncio
import time
import logging
import threading
import multiprocessing
from typing import Dict, List, Any, Optional, Callable, Union, Coroutine
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from contextlib import asynccontextmanager
from queue import Queue, PriorityQueue
import psutil
import numpy as np

from backend.config.settings import get_settings

settings = get_settings()
logger = logging.getLogger(__name__)

@dataclass
class ConcurrencyMetrics:
    """å¹¶å‘æ€§èƒ½æŒ‡æ ‡"""
    task_type: str
    execution_time: float
    worker_type: str  # thread, process, async
    queue_time: float = 0.0
    memory_usage: float = 0.0
    cpu_usage: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)
    success: bool = True
    error_message: Optional[str] = None

@dataclass
class ResourceLimits:
    """èµ„æºé™åˆ¶é…ç½®"""
    max_threads: int = multiprocessing.cpu_count() * 2
    max_processes: int = multiprocessing.cpu_count()
    max_async_tasks: int = 1000
    memory_limit_mb: float = 1024  # 1GB
    cpu_limit_percent: float = 80.0

class ThreadPoolManager:
    """çº¿ç¨‹æ± ç®¡ç†å™¨"""

    def __init__(self, max_workers: int = None):
        self.max_workers = max_workers or ResourceLimits().max_threads
        self.executor = ThreadPoolExecutor(max_workers=self.max_workers)
        self.active_tasks = 0
        self.completed_tasks = 0
        self.failed_tasks = 0
        self._lock = threading.Lock()

    async def submit_task(self, func: Callable, *args, **kwargs) -> Any:
        """æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± """
        loop = asyncio.get_event_loop()

        with self._lock:
            self.active_tasks += 1

        try:
            start_time = time.time()
            result = await loop.run_in_executor(self.executor, func, *args, **kwargs)
            execution_time = time.time() - start_time

            with self._lock:
                self.completed_tasks += 1
                self.active_tasks -= 1

            logger.debug(f"çº¿ç¨‹ä»»åŠ¡å®Œæˆï¼Œè€—æ—¶: {execution_time:.3f}ç§’")
            return result

        except Exception as e:
            with self._lock:
                self.failed_tasks += 1
                self.active_tasks -= 1

            logger.error(f"çº¿ç¨‹ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            raise

    async def submit_batch(self, tasks: List[tuple]) -> List[Any]:
        """æ‰¹é‡æäº¤ä»»åŠ¡"""
        futures = []
        for task_args in tasks:
            func, *args = task_args
            kwargs = {}
            if len(args) > 0 and isinstance(args[-1], dict):
                kwargs = args[-1]
                args = args[:-1]

            future = self.submit_task(func, *args, **kwargs)
            futures.append(future)

        results = await asyncio.gather(*futures, return_exceptions=True)
        return [r for r in results if not isinstance(r, Exception)]

    def get_stats(self) -> Dict[str, Any]:
        """è·å–çº¿ç¨‹æ± ç»Ÿè®¡"""
        with self._lock:
            return {
                "max_workers": self.max_workers,
                "active_tasks": self.active_tasks,
                "completed_tasks": self.completed_tasks,
                "failed_tasks": self.failed_tasks,
                "success_rate": (
                    self.completed_tasks / (self.completed_tasks + self.failed_tasks) * 100
                    if (self.completed_tasks + self.failed_tasks) > 0 else 100
                )
            }

    def shutdown(self):
        """å…³é—­çº¿ç¨‹æ± """
        self.executor.shutdown(wait=True)

class ProcessPoolManager:
    """è¿›ç¨‹æ± ç®¡ç†å™¨"""

    def __init__(self, max_workers: int = None):
        self.max_workers = max_workers or ResourceLimits().max_processes
        self.executor = ProcessPoolExecutor(max_workers=self.max_workers)
        self.active_tasks = 0
        self.completed_tasks = 0
        self.failed_tasks = 0
        self._lock = threading.Lock()

    async def submit_task(self, func: Callable, *args, **kwargs) -> Any:
        """æäº¤ä»»åŠ¡åˆ°è¿›ç¨‹æ± """
        loop = asyncio.get_event_loop()

        with self._lock:
            self.active_tasks += 1

        try:
            start_time = time.time()
            result = await loop.run_in_executor(self.executor, func, *args, **kwargs)
            execution_time = time.time() - start_time

            with self._lock:
                self.completed_tasks += 1
                self.active_tasks -= 1

            logger.debug(f"è¿›ç¨‹ä»»åŠ¡å®Œæˆï¼Œè€—æ—¶: {execution_time:.3f}ç§’")
            return result

        except Exception as e:
            with self._lock:
                self.failed_tasks += 1
                self.active_tasks -= 1

            logger.error(f"è¿›ç¨‹ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            raise

    def get_stats(self) -> Dict[str, Any]:
        """è·å–è¿›ç¨‹æ± ç»Ÿè®¡"""
        with self._lock:
            return {
                "max_workers": self.max_workers,
                "active_tasks": self.active_tasks,
                "completed_tasks": self.completed_tasks,
                "failed_tasks": self.failed_tasks,
                "success_rate": (
                    self.completed_tasks / (self.completed_tasks + self.failed_tasks) * 100
                    if (self.completed_tasks + self.failed_tasks) > 0 else 100
                )
            }

    def shutdown(self):
        """å…³é—­è¿›ç¨‹æ± """
        self.executor.shutdown(wait=True)

class AsyncTaskScheduler:
    """å¼‚æ­¥ä»»åŠ¡è°ƒåº¦å™¨"""

    def __init__(self, max_concurrent: int = None):
        self.max_concurrent = max_concurrent or ResourceLimits().max_async_tasks
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.task_queue = asyncio.Queue()
        self.running_tasks = set()
        self.completed_tasks = 0
        self.failed_tasks = 0
        self.metrics: List[ConcurrencyMetrics] = []

    async def submit_task(self, coro: Coroutine, task_type: str = "unknown") -> Any:
        """æäº¤å¼‚æ­¥ä»»åŠ¡"""
        async with self.semaphore:
            start_time = time.time()
            start_memory = psutil.Process().memory_info().rss / 1024 / 1024
            start_cpu = psutil.cpu_percent()

            self.running_tasks.add(coro)

            try:
                result = await coro
                execution_time = time.time() - start_time
                end_memory = psutil.Process().memory_info().rss / 1024 / 1024
                end_cpu = psutil.cpu_percent()

                # è®°å½•æ€§èƒ½æŒ‡æ ‡
                metric = ConcurrencyMetrics(
                    task_type=task_type,
                    execution_time=execution_time,
                    worker_type="async",
                    memory_usage=end_memory - start_memory,
                    cpu_usage=end_cpu - start_cpu,
                    success=True
                )
                self.metrics.append(metric)
                self.completed_tasks += 1

                logger.debug(f"å¼‚æ­¥ä»»åŠ¡å®Œæˆï¼Œè€—æ—¶: {execution_time:.3f}ç§’")
                return result

            except Exception as e:
                execution_time = time.time() - start_time

                metric = ConcurrencyMetrics(
                    task_type=task_type,
                    execution_time=execution_time,
                    worker_type="async",
                    success=False,
                    error_message=str(e)
                )
                self.metrics.append(metric)
                self.failed_tasks += 1

                logger.error(f"å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                raise

            finally:
                self.running_tasks.discard(coro)

    async def submit_batch(self, tasks: List[tuple]) -> List[Any]:
        """æ‰¹é‡æäº¤å¼‚æ­¥ä»»åŠ¡"""
        futures = []
        for task_args in tasks:
            if len(task_args) == 1:
                coro, task_type = task_args[0], "unknown"
            else:
                coro, task_type = task_args

            future = self.submit_task(coro, task_type)
            futures.append(future)

        results = await asyncio.gather(*futures, return_exceptions=True)
        return [r for r in results if not isinstance(r, Exception)]

    async def get_running_task_count(self) -> int:
        """è·å–æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡æ•°"""
        return len(self.running_tasks)

    def get_stats(self) -> Dict[str, Any]:
        """è·å–å¼‚æ­¥ä»»åŠ¡ç»Ÿè®¡"""
        return {
            "max_concurrent": self.max_concurrent,
            "running_tasks": len(self.running_tasks),
            "completed_tasks": self.completed_tasks,
            "failed_tasks": self.failed_tasks,
            "success_rate": (
                self.completed_tasks / (self.completed_tasks + self.failed_tasks) * 100
                if (self.completed_tasks + self.failed_tasks) > 0 else 100
            ),
            "metrics_count": len(self.metrics)
        }

class LoadBalancer:
    """è´Ÿè½½å‡è¡¡å™¨"""

    def __init__(self, workers: List[str]):
        self.workers = workers
        self.current_index = 0
        self.worker_stats = {worker: {"requests": 0, "response_time": 0.0} for worker in workers}
        self._lock = threading.Lock()

    def get_worker_round_robin(self) -> str:
        """è½®è¯¢é€‰æ‹©å·¥ä½œèŠ‚ç‚¹"""
        with self._lock:
            worker = self.workers[self.current_index]
            self.current_index = (self.current_index + 1) % len(self.workers)
            return worker

    def get_worker_least_connections(self) -> str:
        """æœ€å°‘è¿æ¥é€‰æ‹©å·¥ä½œèŠ‚ç‚¹"""
        with self._lock:
            min_requests = min(self.worker_stats[w]["requests"] for w in self.workers)
            candidates = [w for w in self.workers if self.worker_stats[w]["requests"] == min_requests]
            return candidates[0] if candidates else self.workers[0]

    def get_worker_best_response_time(self) -> str:
        """æœ€ä½³å“åº”æ—¶é—´é€‰æ‹©å·¥ä½œèŠ‚ç‚¹"""
        with self._lock:
            best_worker = min(
                self.workers,
                key=lambda w: self.worker_stats[w]["response_time"]
            )
            return best_worker

    def update_worker_stats(self, worker: str, response_time: float):
        """æ›´æ–°å·¥ä½œèŠ‚ç‚¹ç»Ÿè®¡"""
        with self._lock:
            stats = self.worker_stats[worker]
            stats["requests"] += 1
            # ä½¿ç”¨ç§»åŠ¨å¹³å‡
            stats["response_time"] = (
                stats["response_time"] * 0.9 + response_time * 0.1
            )

    def get_stats(self) -> Dict[str, Any]:
        """è·å–è´Ÿè½½å‡è¡¡ç»Ÿè®¡"""
        with self._lock:
            return {
                "total_workers": len(self.workers),
                "worker_stats": dict(self.worker_stats)
            }

class ConcurrencyOptimizer:
    """å¹¶å‘æ€§èƒ½ä¼˜åŒ–å™¨"""

    def __init__(self):
        self.thread_pool = ThreadPoolManager()
        self.process_pool = ProcessPoolManager()
        self.async_scheduler = AsyncTaskScheduler()
        self.load_balancer = None
        self.resource_limits = ResourceLimits()
        self.metrics: List[ConcurrencyMetrics] = []

    async def optimize_task_execution(
        self,
        func: Callable,
        *args,
        execution_type: str = "auto",
        task_type: str = "unknown",
        **kwargs
    ) -> Any:
        """æ™ºèƒ½ä»»åŠ¡æ‰§è¡Œä¼˜åŒ–"""

        # è‡ªåŠ¨é€‰æ‹©æ‰§è¡Œç±»å‹
        if execution_type == "auto":
            execution_type = await self._select_optimal_execution_type(func, args, kwargs)

        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024
        start_cpu = psutil.cpu_percent()

        try:
            if execution_type == "thread":
                result = await self.thread_pool.submit_task(func, *args, **kwargs)
            elif execution_type == "process":
                result = await self.process_pool.submit_task(func, *args, **kwargs)
            elif execution_type == "async":
                if asyncio.iscoroutinefunction(func):
                    result = await self.async_scheduler.submit_task(func(*args, **kwargs), task_type)
                else:
                    # å°†åŒæ­¥å‡½æ•°è½¬æ¢ä¸ºå¼‚æ­¥
                    result = await self.async_scheduler.submit_task(
                        asyncio.to_thread(func, *args, **kwargs),
                        task_type
                    )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ‰§è¡Œç±»å‹: {execution_type}")

            # è®°å½•æ€§èƒ½æŒ‡æ ‡
            execution_time = time.time() - start_time
            end_memory = psutil.Process().memory_info().rss / 1024 / 1024
            end_cpu = psutil.cpu_percent()

            metric = ConcurrencyMetrics(
                task_type=task_type,
                execution_time=execution_time,
                worker_type=execution_type,
                memory_usage=end_memory - start_memory,
                cpu_usage=end_cpu - start_cpu,
                success=True
            )
            self.metrics.append(metric)

            logger.debug(f"ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œç±»å‹: {execution_type}, è€—æ—¶: {execution_time:.3f}ç§’")
            return result

        except Exception as e:
            execution_time = time.time() - start_time

            metric = ConcurrencyMetrics(
                task_type=task_type,
                execution_time=execution_time,
                worker_type=execution_type,
                success=False,
                error_message=str(e)
            )
            self.metrics.append(metric)

            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            raise

    async def _select_optimal_execution_type(self, func: Callable, args: tuple, kwargs: dict) -> str:
        """æ™ºèƒ½é€‰æ‹©æœ€ä¼˜æ‰§è¡Œç±»å‹"""
        # æ£€æŸ¥CPUä½¿ç”¨ç‡
        cpu_usage = psutil.cpu_percent()

        # æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
        memory = psutil.virtual_memory()
        memory_usage = memory.percent

        # åŸºäºå½“å‰ç³»ç»Ÿè´Ÿè½½å’Œä»»åŠ¡ç‰¹æ€§é€‰æ‹©
        if cpu_usage < 50 and memory_usage < 70:
            # ç³»ç»Ÿè´Ÿè½½è¾ƒä½ï¼Œå¯ä»¥ä½¿ç”¨è¿›ç¨‹æ± 
            return "process"
        elif cpu_usage < 70:
            # ç³»ç»Ÿè´Ÿè½½ä¸­ç­‰ï¼Œä½¿ç”¨çº¿ç¨‹æ± 
            return "thread"
        else:
            # ç³»ç»Ÿè´Ÿè½½è¾ƒé«˜ï¼Œä½¿ç”¨å¼‚æ­¥
            return "async"

    async def execute_parallel_tasks(
        self,
        tasks: List[tuple],
        max_concurrent: int = None,
        execution_type: str = "auto"
    ) -> List[Any]:
        """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªä»»åŠ¡"""
        if max_concurrent is None:
            max_concurrent = min(len(tasks), 10)

        # åˆ†æ‰¹æ‰§è¡Œä»¥é¿å…èµ„æºè¿‡è½½
        results = []
        for i in range(0, len(tasks), max_concurrent):
            batch = tasks[i:i + max_concurrent]
            batch_results = await self._execute_task_batch(batch, execution_type)
            results.extend(batch_results)

            # åœ¨æ‰¹æ¬¡ä¹‹é—´ç¨ä½œåœé¡¿
            if i + max_concurrent < len(tasks):
                await asyncio.sleep(0.1)

        return results

    async def _execute_task_batch(self, tasks: List[tuple], execution_type: str) -> List[Any]:
        """æ‰§è¡Œä»»åŠ¡æ‰¹æ¬¡"""
        futures = []
        for task_args in tasks:
            if len(task_args) == 1:
                func, = task_args
                task_type = "unknown"
            else:
                func, task_type = task_args

            future = self.optimize_task_execution(
                func,
                execution_type=execution_type,
                task_type=task_type
            )
            futures.append(future)

        results = await asyncio.gather(*futures, return_exceptions=True)
        return [r for r in results if not isinstance(r, Exception)]

    def get_performance_report(self, minutes: int = 60) -> Dict[str, Any]:
        """ç”Ÿæˆå¹¶å‘æ€§èƒ½æŠ¥å‘Š"""
        cutoff_time = datetime.now() - timedelta(minutes=minutes)
        recent_metrics = [m for m in self.metrics if m.timestamp > cutoff_time]

        if not recent_metrics:
            return {"status": "no_data", "message": "æš‚æ— å¹¶å‘æ€§èƒ½æ•°æ®"}

        # æŒ‰å·¥ä½œç±»å‹åˆ†ç»„ç»Ÿè®¡
        worker_stats = {}
        for metric in recent_metrics:
            worker_type = metric.worker_type
            if worker_type not in worker_stats:
                worker_stats[worker_type] = {
                    "count": 0,
                    "execution_times": [],
                    "success_count": 0,
                    "memory_usage": [],
                    "cpu_usage": []
                }

            stats = worker_stats[worker_type]
            stats["count"] += 1
            stats["execution_times"].append(metric.execution_time)
            if metric.success:
                stats["success_count"] += 1
            if metric.memory_usage > 0:
                stats["memory_usage"].append(metric.memory_usage)
            if metric.cpu_usage > 0:
                stats["cpu_usage"].append(metric.cpu_usage)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        for worker_type, stats in worker_stats.items():
            times = stats["execution_times"]
            stats["avg_execution_time"] = sum(times) / len(times)
            stats["max_execution_time"] = max(times)
            stats["min_execution_time"] = min(times)
            stats["success_rate"] = (
                stats["success_count"] / stats["count"] * 100
            )

            if stats["memory_usage"]:
                stats["avg_memory_usage"] = sum(stats["memory_usage"]) / len(stats["memory_usage"])
            if stats["cpu_usage"]:
                stats["avg_cpu_usage"] = sum(stats["cpu_usage"]) / len(stats["cpu_usage"])

        return {
            "summary": {
                "total_tasks": len(recent_metrics),
                "successful_tasks": len([m for m in recent_metrics if m.success]),
                "failed_tasks": len([m for m in recent_metrics if not m.success]),
                "overall_success_rate": (
                    len([m for m in recent_metrics if m.success]) / len(recent_metrics) * 100
                ),
                "period_minutes": minutes
            },
            "worker_performance": worker_stats,
            "resource_stats": {
                "thread_pool": self.thread_pool.get_stats(),
                "process_pool": self.process_pool.get_stats(),
                "async_scheduler": self.async_scheduler.get_stats()
            },
            "slow_tasks": [
                {
                    "task_type": m.task_type,
                    "worker_type": m.worker_type,
                    "execution_time": m.execution_time,
                    "timestamp": m.timestamp.isoformat(),
                    "error": m.error_message
                }
                for m in sorted(recent_metrics, key=lambda x: x.execution_time, reverse=True)[:10]
                if m.execution_time > 2.0  # è¶…è¿‡2ç§’çš„ä»»åŠ¡
            ]
        }

    def clear_old_metrics(self, hours: int = 24):
        """æ¸…ç†æ—§çš„æ€§èƒ½æŒ‡æ ‡"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        original_count = len(self.metrics)

        self.metrics = [m for m in self.metrics if m.timestamp > cutoff_time]
        cleaned_count = original_count - len(self.metrics)

        if cleaned_count > 0:
            logger.info(f"æ¸…ç†äº† {cleaned_count} æ¡æ—§çš„å¹¶å‘æ€§èƒ½æŒ‡æ ‡")

    async def shutdown(self):
        """å…³é—­æ‰€æœ‰èµ„æº"""
        self.thread_pool.shutdown()
        self.process_pool.shutdown()

# å…¨å±€å¹¶å‘ä¼˜åŒ–å™¨å®ä¾‹
concurrency_optimizer = ConcurrencyOptimizer()

# è£…é¥°å™¨å‡½æ•°
def run_in_thread_pool(func: Callable):
    """åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œçš„è£…é¥°å™¨"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        return await concurrency_optimizer.optimize_task_execution(
            func, *args, execution_type="thread", task_type=func.__name__, **kwargs
        )
    return wrapper

def run_in_process_pool(func: Callable):
    """åœ¨è¿›ç¨‹æ± ä¸­è¿è¡Œçš„è£…é¥°å™¨"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        return await concurrency_optimizer.optimize_task_execution(
            func, *args, execution_type="process", task_type=func.__name__, **kwargs
        )
    return wrapper

def run_async_optimized(func: Callable):
    """ä¼˜åŒ–çš„å¼‚æ­¥æ‰§è¡Œè£…é¥°å™¨"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        if asyncio.iscoroutinefunction(func):
            return await concurrency_optimizer.optimize_task_execution(
                func, *args, execution_type="async", task_type=func.__name__, **kwargs
            )
        else:
            return await concurrency_optimizer.optimize_task_execution(
                func, *args, execution_type="async", task_type=func.__name__, **kwargs
            )
    return wrapper

# æµ‹è¯•å‡½æ•°
async def test_concurrency_optimization():
    """æµ‹è¯•å¹¶å‘æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½"""
    print("ğŸš€ æµ‹è¯•å¹¶å‘æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½...")

    def cpu_intensive_task(n: int) -> int:
        """CPUå¯†é›†å‹ä»»åŠ¡"""
        total = 0
        for i in range(n):
            total += i * i
        return total

    def io_intensive_task(delay: float) -> str:
        """IOå¯†é›†å‹ä»»åŠ¡"""
        time.sleep(delay)
        return f"IOä»»åŠ¡å®Œæˆï¼Œå»¶è¿Ÿ: {delay}ç§’"

    async def async_task(message: str) -> str:
        """å¼‚æ­¥ä»»åŠ¡"""
        await asyncio.sleep(0.1)
        return f"å¼‚æ­¥ä»»åŠ¡: {message}"

    # æµ‹è¯•ä¸åŒç±»å‹çš„ä»»åŠ¡
    tasks = [
        (cpu_intensive_task, "cpu_task"),
        (io_intensive_task, "io_task"),
        (async_task, "async_task")
    ]

    # å¹¶è¡Œæ‰§è¡Œä»»åŠ¡
    start_time = time.time()
    results = await concurrency_optimizer.execute_parallel_tasks([
        (lambda: cpu_intensive_task(10000), "cpu_intensive"),
        (lambda: io_intensive_task(0.2), "io_intensive"),
        (lambda: async_task("test"), "async_task")
    ])
    end_time = time.time()

    print(f"å¹¶è¡Œæ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.3f}ç§’")
    print(f"ä»»åŠ¡ç»“æœ: {results}")

    # è·å–æ€§èƒ½æŠ¥å‘Š
    report = concurrency_optimizer.get_performance_report()
    print(f"\nğŸ“Š å¹¶å‘æ€§èƒ½æŠ¥å‘Š:")
    print(f"æ€»ä»»åŠ¡æ•°: {report['summary']['total_tasks']}")
    print(f"æˆåŠŸç‡: {report['summary']['overall_success_rate']:.1f}%")

    for worker_type, stats in report['worker_performance'].items():
        print(f"{worker_type}: å¹³å‡æ‰§è¡Œæ—¶é—´ {stats['avg_execution_time']:.3f}ç§’")

if __name__ == "__main__":
    import asyncio
    from functools import wraps

    asyncio.run(test_concurrency_optimization())