"""
ä»£ç è´¨é‡æ”¹è¿›å’Œæ ‡å‡†åŒ–æ¨¡å—
Week 6 Day 3: ä»£ç é‡æ„å’Œæ¶æ„ä¼˜åŒ– - ä»£ç è´¨é‡æ”¹è¿›
å®ç°ä»£ç æ ‡å‡†åŒ–ã€è´¨é‡æ£€æŸ¥ã€è‡ªåŠ¨åŒ–æ ¼å¼åŒ–ç­‰åŠŸèƒ½
"""

import ast
import re
import os
import subprocess
import logging
from typing import Dict, List, Any, Optional, Set, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
import json
from enum import Enum

logger = logging.getLogger(__name__)

class QualityLevel(Enum):
    """è´¨é‡ç­‰çº§"""
    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"

class IssueType(Enum):
    """é—®é¢˜ç±»å‹"""
    STYLE = "style"
    LOGIC = "logic"
    NAMING = "naming"
    DOCUMENTATION = "documentation"
    SECURITY = "security"
    PERFORMANCE = "performance"
    MAINTAINABILITY = "maintainability"

@dataclass
class CodeIssue:
    """ä»£ç é—®é¢˜"""
    file_path: str
    line_number: int
    column_number: int
    issue_type: IssueType
    severity: str  # info, warning, error, critical
    message: str
    rule_id: str
    suggestion: str = ""
    auto_fixable: bool = False

@dataclass
class QualityMetrics:
    """è´¨é‡æŒ‡æ ‡"""
    file_path: str
    lines_of_code: int
    complexity: int
    maintainability_index: float
    test_coverage: float
    duplication_percentage: float
    issues_count: int
    quality_score: float
    quality_level: QualityLevel

class CodeStandards:
    """ä»£ç æ ‡å‡†é…ç½®"""

    # å‘½åè§„èŒƒ
    NAMING_PATTERNS = {
        'class': r'^[A-Z][a-zA-Z0-9]*$',
        'function': r'^[a-z][a-zA-Z0-9_]*$',
        'variable': r'^[a-z][a-zA-Z0-9_]*$',
        'constant': r'^[A-Z][A-Z0-9_]*$',
        'module': r'^[a-z][a-z0-9_]*$'
    }

    # å¤æ‚åº¦é™åˆ¶
    MAX_FUNCTION_LENGTH = 50
    MAX_CLASS_LENGTH = 200
    MAX_NESTING_DEPTH = 4
    MAX_FUNCTION_COMPLEXITY = 10

    # æ–‡æ¡£è¦æ±‚
    REQUIRE_DOCSTRINGS = True
    MIN_COMMENT_RATIO = 0.1

    # æ€§èƒ½è¦æ±‚
    MAX_IMPORTS_PER_FILE = 20
    MAX_DEPENDENCIES_PER_MODULE = 10

class CodeAnalyzer:
    """ä»£ç åˆ†æå™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.standards = CodeStandards()
        self.issues: List[CodeIssue] = []
        self.metrics: Dict[str, QualityMetrics] = {}

    def analyze_project(self) -> Dict[str, Any]:
        """åˆ†ææ•´ä¸ªé¡¹ç›®ä»£ç è´¨é‡"""
        logger.info("å¼€å§‹ä»£ç è´¨é‡åˆ†æ...")

        python_files = self._find_python_files()

        for file_path in python_files:
            try:
                # åˆ†ææ–‡ä»¶
                self._analyze_file(file_path)

                # è®¡ç®—è´¨é‡æŒ‡æ ‡
                metrics = self._calculate_quality_metrics(file_path)
                self.metrics[str(file_path)] = metrics

            except Exception as e:
                logger.error(f"åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")

        return self._generate_quality_report()

    def _find_python_files(self) -> List[Path]:
        """æŸ¥æ‰¾Pythonæ–‡ä»¶"""
        python_files = []
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡å¿½ç•¥ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in [
                '__pycache__', 'venv', 'env', 'node_modules', 'migrations'
            ]]

            for file in files:
                if file.endswith('.py'):
                    python_files.append(Path(root) / file)

        return python_files

    def _analyze_file(self, file_path: Path):
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)

            # æ£€æŸ¥å‘½åè§„èŒƒ
            self._check_naming_conventions(tree, file_path)

            # æ£€æŸ¥ä»£ç å¤æ‚åº¦
            self._check_complexity(tree, file_path)

            # æ£€æŸ¥æ–‡æ¡£
            self._check_documentation(tree, content, file_path)

            # æ£€æŸ¥ä»£ç é£æ ¼
            self._check_code_style(content, file_path)

            # æ£€æŸ¥å¯¼å…¥
            self._check_imports(tree, file_path)

            # æ£€æŸ¥å®‰å…¨æ€§
            self._check_security(content, file_path)

            # æ£€æŸ¥æ€§èƒ½é—®é¢˜
            self._check_performance_issues(content, file_path)

        except Exception as e:
            logger.error(f"æ–‡ä»¶åˆ†æå¤±è´¥ {file_path}: {e}")

    def _check_naming_conventions(self, tree: ast.AST, file_path: Path):
        """æ£€æŸ¥å‘½åè§„èŒƒ"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                self._check_name(node.name, 'class', node.lineno, node.col_offset, file_path)

                # æ£€æŸ¥æ–¹æ³•å‘½å
                for item in node.body:
                    if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):
                        if not item.name.startswith('_') or item.name.startswith('__'):
                            self._check_name(item.name, 'function', item.lineno, item.col_offset, file_path)

            elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                if not hasattr(node, 'parent_class'):  # ä¸åœ¨ç±»ä¸­çš„å‡½æ•°
                    self._check_name(node.name, 'function', node.lineno, node.col_offset, file_path)

            elif isinstance(node, ast.Name) and isinstance(node.ctx, ast.Store):
                # æ£€æŸ¥å˜é‡å‘½å
                if node.id.isupper():
                    self._check_name(node.id, 'constant', node.lineno, node.col_offset, file_path)
                else:
                    self._check_name(node.id, 'variable', node.lineno, node.col_offset, file_path)

    def _check_name(self, name: str, name_type: str, line: int, col: int, file_path: Path):
        """æ£€æŸ¥åç§°æ˜¯å¦ç¬¦åˆè§„èŒƒ"""
        pattern = self.standards.NAMING_PATTERNS.get(name_type)
        if pattern and not re.match(pattern, name):
            self.issues.append(CodeIssue(
                file_path=str(file_path),
                line_number=line,
                column_number=col,
                issue_type=IssueType.NAMING,
                severity="warning",
                message=f"{name_type}å‘½åä¸è§„èŒƒ: '{name}'",
                rule_id=f"NAMING_{name_type.upper()}",
                suggestion=f"åº”ç¬¦åˆæ¨¡å¼: {pattern}",
                auto_fixable=False
            ))

    def _check_complexity(self, tree: ast.AST, file_path: Path):
        """æ£€æŸ¥ä»£ç å¤æ‚åº¦"""
        # æ£€æŸ¥å‡½æ•°é•¿åº¦
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                func_length = node.end_lineno - node.lineno if hasattr(node, 'end_lineno') else 0

                if func_length > self.standards.MAX_FUNCTION_LENGTH:
                    self.issues.append(CodeIssue(
                        file_path=str(file_path),
                        line_number=node.lineno,
                        column_number=0,
                        issue_type=IssueType.MAINTAINABILITY,
                        severity="warning",
                        message=f"å‡½æ•°è¿‡é•¿: {func_length} è¡Œ (å»ºè®® < {self.standards.MAX_FUNCTION_LENGTH})",
                        rule_id="FUNCTION_LENGTH",
                        suggestion="è€ƒè™‘æ‹†åˆ†ä¸ºæ›´å°çš„å‡½æ•°",
                        auto_fixable=False
                    ))

                # æ£€æŸ¥å¤æ‚åº¦
                complexity = self._calculate_function_complexity(node)
                if complexity > self.standards.MAX_FUNCTION_COMPLEXITY:
                    self.issues.append(CodeIssue(
                        file_path=str(file_path),
                        line_number=node.lineno,
                        column_number=0,
                        issue_type=IssueType.MAINTAINABILITY,
                        severity="warning",
                        message=f"å‡½æ•°å¤æ‚åº¦è¿‡é«˜: {complexity} (å»ºè®® < {self.standards.MAX_FUNCTION_COMPLEXITY})",
                        rule_id="FUNCTION_COMPLEXITY",
                        suggestion="ç®€åŒ–é€»è¾‘æˆ–æå–å­å‡½æ•°",
                        auto_fixable=False
                    ))

        # æ£€æŸ¥ç±»é•¿åº¦
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                class_length = node.end_lineno - node.lineno if hasattr(node, 'end_lineno') else 0

                if class_length > self.standards.MAX_CLASS_LENGTH:
                    self.issues.append(CodeIssue(
                        file_path=str(file_path),
                        line_number=node.lineno,
                        column_number=0,
                        issue_type=IssueType.MAINTAINABILITY,
                        severity="warning",
                        message=f"ç±»è¿‡é•¿: {class_length} è¡Œ (å»ºè®® < {self.standards.MAX_CLASS_LENGTH})",
                        rule_id="CLASS_LENGTH",
                        suggestion="è€ƒè™‘æ‹†åˆ†ä¸ºå¤šä¸ªç±»æˆ–ä½¿ç”¨ç»„åˆ",
                        auto_fixable=False
                    ))

    def _calculate_function_complexity(self, node: ast.FunctionDef) -> int:
        """è®¡ç®—å‡½æ•°å¤æ‚åº¦"""
        complexity = 1  # åŸºç¡€å¤æ‚åº¦

        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
            elif isinstance(child, ast.ListComp) or isinstance(child, ast.DictComp):
                complexity += 1

        return complexity

    def _check_documentation(self, tree: ast.AST, content: str, file_path: Path):
        """æ£€æŸ¥æ–‡æ¡£"""
        lines = content.split('\n')
        comment_lines = len([line for line in lines if line.strip().startswith('#')])
        code_lines = len([line for line in lines if line.strip() and not line.strip().startswith('#')])

        comment_ratio = comment_lines / code_lines if code_lines > 0 else 0

        if comment_ratio < self.standards.MIN_COMMENT_RATIO and code_lines > 20:
            self.issues.append(CodeIssue(
                file_path=str(file_path),
                line_number=1,
                column_number=0,
                issue_type=IssueType.DOCUMENTATION,
                severity="info",
                message=f"æ³¨é‡Šæ¯”ä¾‹è¿‡ä½: {comment_ratio:.1%} (å»ºè®® > {self.standards.MIN_COMMENT_RATIO:.1%})",
                rule_id="COMMENT_RATIO",
                suggestion="æ·»åŠ é€‚å½“çš„æ³¨é‡Šå’Œæ–‡æ¡£å­—ç¬¦ä¸²",
                auto_fixable=False
            ))

        # æ£€æŸ¥å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                if not ast.get_docstring(node) and node.name != '__init__':
                    self.issues.append(CodeIssue(
                        file_path=str(file_path),
                        line_number=node.lineno,
                        column_number=0,
                        issue_type=IssueType.DOCUMENTATION,
                        severity="info",
                        message=f"å‡½æ•° '{node.name}' ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²",
                        rule_id="DOCSTRING_MISSING",
                        suggestion="æ·»åŠ å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²",
                        auto_fixable=False
                    ))

    def _check_code_style(self, content: str, file_path: Path):
        """æ£€æŸ¥ä»£ç é£æ ¼"""
        lines = content.split('\n')

        for i, line in enumerate(lines, 1):
            # æ£€æŸ¥è¡Œé•¿åº¦
            if len(line) > 120:
                self.issues.append(CodeIssue(
                    file_path=str(file_path),
                    line_number=i,
                    column_number=120,
                    issue_type=IssueType.STYLE,
                    severity="info",
                    message=f"è¡Œè¿‡é•¿: {len(line)} å­—ç¬¦ (å»ºè®® < 120)",
                    rule_id="LINE_LENGTH",
                    suggestion="æ¢è¡Œæˆ–ç®€åŒ–è¡¨è¾¾å¼",
                    auto_fixable=True
                ))

            # æ£€æŸ¥å°¾éšç©ºæ ¼
            if line.endswith(' '):
                self.issues.append(CodeIssue(
                    file_path=str(file_path),
                    line_number=i,
                    column_number=len(line.rstrip()),
                    issue_type=IssueType.STYLE,
                    severity="info",
                    message="è¡Œå°¾æœ‰å¤šä½™ç©ºæ ¼",
                    rule_id="TRAILING_WHITESPACE",
                    suggestion="åˆ é™¤è¡Œå°¾ç©ºæ ¼",
                    auto_fixable=True
                ))

            # æ£€æŸ¥åˆ¶è¡¨ç¬¦
            if '\t' in line:
                self.issues.append(CodeIssue(
                    file_path=str(file_path),
                    line_number=i,
                    column_number=line.find('\t'),
                    issue_type=IssueType.STYLE,
                    severity="warning",
                    message="ä½¿ç”¨äº†åˆ¶è¡¨ç¬¦ï¼ˆå»ºè®®ä½¿ç”¨ç©ºæ ¼ï¼‰",
                    rule_id="TAB_CHARACTER",
                    suggestion="å°†åˆ¶è¡¨ç¬¦æ›¿æ¢ä¸ºç©ºæ ¼",
                    auto_fixable=True
                ))

    def _check_imports(self, tree: ast.AST, file_path: Path):
        """æ£€æŸ¥å¯¼å…¥"""
        imports = [node for node in ast.walk(tree) if isinstance(node, (ast.Import, ast.ImportFrom))]

        if len(imports) > self.standards.MAX_IMPORTS_PER_FILE:
            self.issues.append(CodeIssue(
                file_path=str(file_path),
                line_number=1,
                column_number=0,
                issue_type=IssueType.MAINTAINABILITY,
                severity="warning",
                message=f"å¯¼å…¥è¿‡å¤š: {len(imports)} ä¸ª (å»ºè®® < {self.standards.MAX_IMPORTS_PER_FILE})",
                rule_id="IMPORT_COUNT",
                suggestion="è€ƒè™‘é‡æ–°ç»„ç»‡ä»£ç æˆ–å‡å°‘ä¾èµ–",
                auto_fixable=False
            ))

        # æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥
        used_names = set()
        for node in ast.walk(tree):
            if isinstance(node, ast.Name):
                used_names.add(node.id)

        for imp in imports:
            if isinstance(imp, ast.Import):
                for alias in imp.names:
                    name = alias.asname if alias.asname else alias.name
                    if name not in used_names:
                        self.issues.append(CodeIssue(
                            file_path=str(file_path),
                            line_number=imp.lineno,
                            column_number=imp.col_offset,
                            issue_type=IssueType.MAINTAINABILITY,
                            severity="info",
                            message=f"æœªä½¿ç”¨çš„å¯¼å…¥: {name}",
                            rule_id="UNUSED_IMPORT",
                            suggestion="åˆ é™¤æœªä½¿ç”¨çš„å¯¼å…¥",
                            auto_fixable=True
                        ))

    def _check_security(self, content: str, file_path: Path):
        """æ£€æŸ¥å®‰å…¨é—®é¢˜"""
        lines = content.split('\n')

        # æ£€æŸ¥ç¡¬ç¼–ç å¯†ç 
        password_patterns = [
            r'password\s*=\s*["\'][^"\']+["\']',
            r'passwd\s*=\s*["\'][^"\']+["\']',
            r'secret\s*=\s*["\'][^"\']+["\']',
            r'api_key\s*=\s*["\'][^"\']+["\']',
            r'token\s*=\s*["\'][^"\']+["\']'
        ]

        for i, line in enumerate(lines, 1):
            for pattern in password_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    self.issues.append(CodeIssue(
                        file_path=str(file_path),
                        line_number=i,
                        column_number=0,
                        issue_type=IssueType.SECURITY,
                        severity="critical",
                        message="æ£€æµ‹åˆ°ç¡¬ç¼–ç çš„æ•æ„Ÿä¿¡æ¯",
                        rule_id="HARDCODED_SECRET",
                        suggestion="ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶",
                        auto_fixable=False
                    ))

        # æ£€æŸ¥SQLæ³¨å…¥é£é™©
        sql_patterns = [
            r'execute\s*\(\s*["\'].*\+.*["\']',
            r'query\s*\(\s*["\'].*\+.*["\']'
        ]

        for i, line in enumerate(lines, 1):
            for pattern in sql_patterns:
                if re.search(pattern, line):
                    self.issues.append(CodeIssue(
                        file_path=str(file_path),
                        line_number=i,
                        column_number=0,
                        issue_type=IssueType.SECURITY,
                        severity="critical",
                        message="å¯èƒ½å­˜åœ¨SQLæ³¨å…¥é£é™©",
                        rule_id="SQL_INJECTION",
                        suggestion="ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢",
                        auto_fixable=False
                    ))

    def _check_performance_issues(self, content: str, file_path: Path):
        """æ£€æŸ¥æ€§èƒ½é—®é¢˜"""
        lines = content.split('\n')

        # æ£€æŸ¥å¾ªç¯ä¸­çš„é‡å¤è®¡ç®—
        for i, line in enumerate(lines, 1):
            # æ£€æŸ¥åœ¨å¾ªç¯ä¸­è°ƒç”¨len()
            if re.search(r'for.*in.*range\s*\(\s*len\s*\(', line):
                self.issues.append(CodeIssue(
                    file_path=str(file_path),
                    line_number=i,
                    column_number=0,
                    issue_type=IssueType.PERFORMANCE,
                    severity="info",
                    message="å¾ªç¯ä¸­é‡å¤è®¡ç®—len()",
                    rule_id="LEN_IN_LOOP",
                    suggestion="åœ¨å¾ªç¯å¤–è®¡ç®—len()",
                    auto_fixable=False
                ))

            # æ£€æŸ¥åˆ—è¡¨æ¨å¯¼å¼ä¸­çš„å¤æ‚æ“ä½œ
            if 'for' in line and 'in' in line and line.count('[') > 1:
                self.issues.append(CodeIssue(
                    file_path=str(file_path),
                    line_number=i,
                    column_number=0,
                    issue_type=IssueType.PERFORMANCE,
                    severity="info",
                    message="å¤æ‚çš„åˆ—è¡¨æ¨å¯¼å¼å¯èƒ½å½±å“æ€§èƒ½",
                    rule_id="COMPLEX_LIST_COMPREHENSION",
                    suggestion="è€ƒè™‘ä½¿ç”¨ç”Ÿæˆå™¨æˆ–æ™®é€šå¾ªç¯",
                    auto_fixable=False
                ))

    def _calculate_quality_metrics(self, file_path: Path) -> QualityMetrics:
        """è®¡ç®—è´¨é‡æŒ‡æ ‡"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)
            lines = content.split('\n')

            # åŸºç¡€æŒ‡æ ‡
            loc = len([line for line in lines if line.strip()])
            complexity = self._calculate_file_complexity(tree)

            # å¯ç»´æŠ¤æ€§æŒ‡æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
            maintainability_index = max(0, 100 - complexity * 2)

            # æµ‹è¯•è¦†ç›–ç‡ï¼ˆæ¨¡æ‹Ÿï¼‰
            test_coverage = 0.0  # å®é™…åº”è¯¥ä»æµ‹è¯•å·¥å…·è·å–

            # é‡å¤ç‡ï¼ˆæ¨¡æ‹Ÿï¼‰
            duplication_percentage = 0.0  # å®é™…åº”è¯¥è®¡ç®—ä»£ç é‡å¤

            # é—®é¢˜æ•°é‡
            issues_count = len([issue for issue in self.issues if issue.file_path == str(file_path)])

            # è´¨é‡è¯„åˆ†
            quality_score = max(0, 100 - issues_count * 5 - complexity * 2)

            # è´¨é‡ç­‰çº§
            if quality_score >= 90:
                quality_level = QualityLevel.EXCELLENT
            elif quality_score >= 75:
                quality_level = QualityLevel.GOOD
            elif quality_score >= 60:
                quality_level = QualityLevel.FAIR
            else:
                quality_level = QualityLevel.POOR

            return QualityMetrics(
                file_path=str(file_path),
                lines_of_code=loc,
                complexity=complexity,
                maintainability_index=maintainability_index,
                test_coverage=test_coverage,
                duplication_percentage=duplication_percentage,
                issues_count=issues_count,
                quality_score=quality_score,
                quality_level=quality_level
            )

        except Exception as e:
            logger.error(f"è®¡ç®—è´¨é‡æŒ‡æ ‡å¤±è´¥ {file_path}: {e}")
            return QualityMetrics(
                file_path=str(file_path),
                lines_of_code=0,
                complexity=0,
                maintainability_index=0,
                test_coverage=0,
                duplication_percentage=0,
                issues_count=0,
                quality_score=0,
                quality_level=QualityLevel.POOR
            )

    def _calculate_file_complexity(self, tree: ast.AST) -> int:
        """è®¡ç®—æ–‡ä»¶å¤æ‚åº¦"""
        complexity = 0
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                complexity += self._calculate_function_complexity(node)
            elif isinstance(node, ast.ClassDef):
                complexity += 1  # ç±»æœ¬èº«çš„å¤æ‚åº¦
        return complexity

    def _generate_quality_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        # ç»Ÿè®¡é—®é¢˜
        issues_by_type = {}
        issues_by_severity = {}
        auto_fixable_count = 0

        for issue in self.issues:
            # æŒ‰ç±»å‹ç»Ÿè®¡
            if issue.issue_type.value not in issues_by_type:
                issues_by_type[issue.issue_type.value] = 0
            issues_by_type[issue.issue_type.value] += 1

            # æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
            if issue.severity not in issues_by_severity:
                issues_by_severity[issue.severity] = 0
            issues_by_severity[issue.severity] += 1

            # ç»Ÿè®¡å¯è‡ªåŠ¨ä¿®å¤
            if issue.auto_fixable:
                auto_fixable_count += 1

        # è®¡ç®—æ€»ä½“æŒ‡æ ‡
        total_files = len(self.metrics)
        total_loc = sum(m.lines_of_code for m in self.metrics.values())
        avg_complexity = sum(m.complexity for m in self.metrics.values()) / total_files if total_files > 0 else 0
        avg_quality_score = sum(m.quality_score for m in self.metrics.values()) / total_files if total_files > 0 else 0

        # è´¨é‡åˆ†å¸ƒ
        quality_distribution = {}
        for level in QualityLevel:
            quality_distribution[level.value] = len([m for m in self.metrics.values() if m.quality_level == level])

        return {
            "summary": {
                "total_files": total_files,
                "total_lines_of_code": total_loc,
                "average_complexity": round(avg_complexity, 2),
                "average_quality_score": round(avg_quality_score, 2),
                "total_issues": len(self.issues),
                "auto_fixable_issues": auto_fixable_count
            },
            "issues": {
                "by_type": issues_by_type,
                "by_severity": issues_by_severity,
                "items": [
                    {
                        "file_path": issue.file_path,
                        "line_number": issue.line_number,
                        "column_number": issue.column_number,
                        "type": issue.issue_type.value,
                        "severity": issue.severity,
                        "message": issue.message,
                        "rule_id": issue.rule_id,
                        "suggestion": issue.suggestion,
                        "auto_fixable": issue.auto_fixable
                    }
                    for issue in sorted(self.issues, key=lambda x: (
                        {"critical": 4, "error": 3, "warning": 2, "info": 1}[x.severity],
                        x.line_number
                    ), reverse=True)
                ]
            },
            "quality_metrics": {
                "distribution": quality_distribution,
                "files": [
                    {
                        "file_path": metrics.file_path,
                        "lines_of_code": metrics.lines_of_code,
                        "complexity": metrics.complexity,
                        "maintainability_index": metrics.maintainability_index,
                        "quality_score": metrics.quality_score,
                        "quality_level": metrics.quality_level.value,
                        "issues_count": metrics.issues_count
                    }
                    for metrics in sorted(self.metrics.values(), key=lambda x: x.quality_score)
                ]
            },
            "generated_at": datetime.now().isoformat()
        }

class CodeFormatter:
    """ä»£ç æ ¼å¼åŒ–å·¥å…·"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)

    def format_project(self) -> Dict[str, Any]:
        """æ ¼å¼åŒ–æ•´ä¸ªé¡¹ç›®"""
        results = {
            "black": self._run_black(),
            "isort": self._run_isort(),
            "autopep8": self._run_autopep8()
        }

        return {
            "success": all(result["success"] for result in results.values()),
            "tools": results
        }

    def _run_black(self) -> Dict[str, Any]:
        """è¿è¡ŒBlackæ ¼å¼åŒ–"""
        try:
            result = subprocess.run(
                ["black", "--check", "--diff", str(self.project_root)],
                capture_output=True,
                text=True,
                timeout=300
            )

            return {
                "success": result.returncode == 0,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "needs_formatting": result.returncode != 0
            }

        except subprocess.TimeoutExpired:
            return {"success": False, "error": "æ ¼å¼åŒ–è¶…æ—¶"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def _run_isort(self) -> Dict[str, Any]:
        """è¿è¡Œisortæ’åºå¯¼å…¥"""
        try:
            result = subprocess.run(
                ["isort", "--check-only", "--diff", str(self.project_root)],
                capture_output=True,
                text=True,
                timeout=300
            )

            return {
                "success": result.returncode == 0,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "needs_sorting": result.returncode != 0
            }

        except subprocess.TimeoutExpired:
            return {"success": False, "error": "æ’åºè¶…æ—¶"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def _run_autopep8(self) -> Dict[str, Any]:
        """è¿è¡Œautopep8"""
        try:
            result = subprocess.run(
                ["autopep8", "--diff", "--recursive", str(self.project_root)],
                capture_output=True,
                text=True,
                timeout=300
            )

            return {
                "success": result.returncode == 0,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "needs_fixing": result.stdout.strip() != ""
            }

        except subprocess.TimeoutExpired:
            return {"success": False, "error": "ä¿®å¤è¶…æ—¶"}
        except Exception as e:
            return {"success": False, "error": str(e)}

class CodeQualityManager:
    """ä»£ç è´¨é‡ç®¡ç†å™¨"""

    def __init__(self, project_root: str):
        self.project_root = project_root
        self.analyzer = CodeAnalyzer(project_root)
        self.formatter = CodeFormatter(project_root)

    def run_quality_check(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„ä»£ç è´¨é‡æ£€æŸ¥"""
        logger.info("å¼€å§‹ä»£ç è´¨é‡æ£€æŸ¥...")

        # ä»£ç åˆ†æ
        analysis_report = self.analyzer.analyze_project()

        # ä»£ç æ ¼å¼åŒ–æ£€æŸ¥
        format_report = self.formatter.format_project()

        return {
            "analysis": analysis_report,
            "formatting": format_report,
            "overall_quality": self._calculate_overall_quality(analysis_report, format_report)
        }

    def _calculate_overall_quality(self, analysis_report: Dict, format_report: Dict) -> Dict[str, Any]:
        """è®¡ç®—æ€»ä½“è´¨é‡è¯„åˆ†"""
        quality_score = analysis_report["summary"]["average_quality_score"]

        # æ ¼å¼åŒ–å½±å“è¯„åˆ†
        if not format_report["success"]:
            quality_score -= 10

        # ç¡®å®šç­‰çº§
        if quality_score >= 90:
            grade = "A"
        elif quality_score >= 80:
            grade = "B"
        elif quality_score >= 70:
            grade = "C"
        elif quality_score >= 60:
            grade = "D"
        else:
            grade = "F"

        return {
            "score": max(0, quality_score),
            "grade": grade,
            "status": "excellent" if grade in ["A", "B"] else "needs_improvement"
        }

# æµ‹è¯•å‡½æ•°
def test_code_quality():
    """æµ‹è¯•ä»£ç è´¨é‡æ£€æŸ¥"""
    print("ğŸ” æµ‹è¯•ä»£ç è´¨é‡æ£€æŸ¥...")

    quality_manager = CodeQualityManager("/Users/chiyingjie/code/git/ai-hub/backend")
    report = quality_manager.run_quality_check()

    print(f"\nğŸ“Š ä»£ç è´¨é‡æŠ¥å‘Š:")
    print(f"æ€»æ–‡ä»¶æ•°: {report['analysis']['summary']['total_files']}")
    print(f"æ€»ä»£ç è¡Œæ•°: {report['analysis']['summary']['total_lines_of_code']}")
    print(f"å¹³å‡è´¨é‡è¯„åˆ†: {report['analysis']['summary']['average_quality_score']}")
    print(f"æ€»é—®é¢˜æ•°: {report['analysis']['summary']['total_issues']}")
    print(f"å¯è‡ªåŠ¨ä¿®å¤: {report['analysis']['summary']['auto_fixable_issues']}")

    print(f"\nğŸ“ æ ¼å¼åŒ–æ£€æŸ¥:")
    print(f"æ ¼å¼åŒ–çŠ¶æ€: {'é€šè¿‡' if report['formatting']['success'] else 'éœ€è¦æ ¼å¼åŒ–'}")

    print(f"\nğŸ¯ æ€»ä½“è´¨é‡:")
    print(f"è¯„åˆ†: {report['overall_quality']['score']}")
    print(f"ç­‰çº§: {report['overall_quality']['grade']}")
    print(f"çŠ¶æ€: {report['overall_quality']['status']}")

if __name__ == "__main__":
    test_code_quality()