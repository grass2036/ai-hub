#!/bin/bash
# AI Hub ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²è„šæœ¬
# Week 6 Day 4: ç”Ÿäº§ç¯å¢ƒå‡†å¤‡å’Œéƒ¨ç½²é…ç½®

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥ä¾èµ–
check_dependencies() {
    log_info "æ£€æŸ¥éƒ¨ç½²ä¾èµ–..."

    # æ£€æŸ¥Docker
    if ! command -v docker &> /dev/null; then
        log_error "Docker æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Docker"
        exit 1
    fi

    # æ£€æŸ¥Docker Compose
    if ! command -v docker-compose &> /dev/null; then
        log_error "Docker Compose æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Docker Compose"
        exit 1
    fi

    # æ£€æŸ¥kubectl (å¦‚æœä½¿ç”¨Kubernetes)
    if command -v kubectl &> /dev/null; then
        log_info "Kubernetes å·²å®‰è£…"
    fi

    # æ£€æŸ¥git
    if ! command -v git &> /dev/null; then
        log_error "Git æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Git"
        exit 1
    fi

    log_success "æ‰€æœ‰ä¾èµ–æ£€æŸ¥é€šè¿‡"
}

# ç¯å¢ƒéªŒè¯
validate_environment() {
    log_info "éªŒè¯éƒ¨ç½²ç¯å¢ƒ..."

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if [ -z "$ENVIRONMENT" ]; then
        export ENVIRONMENT="production"
    fi

    log_info "éƒ¨ç½²ç¯å¢ƒ: $ENVIRONMENT"

    # æ£€æŸ¥å¿…è¦ç›®å½•
    local required_dirs=("config" "secrets" "logs" "uploads" "monitoring" "nginx")
    for dir in "${required_dirs[@]}"; do
        if [ ! -d "$dir" ]; then
            log_info "åˆ›å»ºç›®å½•: $dir"
            mkdir -p "$dir"
        fi
    done

    # è®¾ç½®ç›®å½•æƒé™
    chmod 700 secrets
    chmod 755 logs uploads

    log_success "ç¯å¢ƒéªŒè¯å®Œæˆ"
}

# ç”Ÿæˆé…ç½®
generate_config() {
    log_info "ç”Ÿæˆéƒ¨ç½²é…ç½®..."

    # è¿è¡ŒPythoné…ç½®ç”Ÿæˆè„šæœ¬
    python -m backend.core.production_config

    # ç”Ÿæˆç¯å¢ƒå˜é‡æ–‡ä»¶
    if [ ! -f ".env.prod" ]; then
        python -c "
from backend.core.production_config import config_manager
config = config_manager.load_config()
with open('.env.prod', 'w') as f:
    f.write(config_manager.get_env_file_content(config))
"
        log_success "ç¯å¢ƒå˜é‡æ–‡ä»¶å·²ç”Ÿæˆ: .env.prod"
    fi

    # ç”Ÿæˆç”Ÿäº§ç¯å¢ƒDocker Composeæ–‡ä»¶
    if [ ! -f "docker-compose.prod.yml" ]; then
        python -c "
from backend.core.production_config import config_manager
config = config_manager.load_config()
with open('docker-compose.prod.yml', 'w') as f:
    f.write(config_manager.create_docker_compose_prod(config))
"
        log_success "Docker Composeé…ç½®å·²ç”Ÿæˆ: docker-compose.prod.yml"
    fi

    # ç”ŸæˆNginxé…ç½®
    if [ ! -f "nginx/nginx.conf" ]; then
        cat > nginx/nginx.conf << 'EOF'
# AI Hub ç”Ÿäº§ç¯å¢ƒ Nginx é…ç½®
events {
    worker_connections 1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log;

    # Gzipå‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # ä¸Šæ¸¸æœåŠ¡å™¨
    upstream backend {
        server backend:8000;
    }

    # HTTPé‡å®šå‘åˆ°HTTPS
    server {
        listen 80;
        server_name _;
        return 301 https://$server_name$request_uri;
    }

    # HTTPSä¸»é…ç½®
    server {
        listen 443 ssl http2;
        server_name aihub.example.com;

        # SSLé…ç½®
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # å®‰å…¨å¤´
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

        # é™æ€æ–‡ä»¶
        location /static/ {
            alias /app/static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # APIä»£ç†
        location /api/ {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # è¶…æ—¶è®¾ç½®
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # å¥åº·æ£€æŸ¥
        location /health {
            proxy_pass http://backend/health;
            access_log off;
        }

        # é»˜è®¤ä»£ç†
        location / {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}
EOF
        log_success "Nginxé…ç½®å·²ç”Ÿæˆ: nginx/nginx.conf"
    fi

    # ç”ŸæˆPrometheusé…ç½®
    if [ ! -f "monitoring/prometheus.yml" ]; then
        mkdir -p monitoring
        cat > monitoring/prometheus.yml << 'EOF'
# Prometheus é…ç½®
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "rules/*.yml"

scrape_configs:
  - job_name: 'ai-hub-backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'ai-hub-nginx'
    static_configs:
      - targets: ['nginx:9113']
    scrape_interval: 30s
EOF
        log_success "Prometheusé…ç½®å·²ç”Ÿæˆ: monitoring/prometheus.yml"
    fi

    # ç”ŸæˆGrafanaä»ªè¡¨æ¿é…ç½®
    if [ ! -f "monitoring/grafana/dashboards/ai-hub-overview.json" ]; then
        mkdir -p monitoring/grafana/dashboards
        cat > monitoring/grafana/dashboards/ai-hub-overview.json << 'EOF'
{
  "dashboard": {
    "title": "AI Hub å¹³å°æ¦‚è§ˆ",
    "panels": [
      {
        "title": "APIè¯·æ±‚æ•°",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      },
      {
        "title": "æ´»è·ƒç”¨æˆ·æ•°",
        "type": "stat",
        "targets": [
          {
            "expr": "active_users_total",
            "legendFormat": "æ´»è·ƒç”¨æˆ·"
          }
        ]
      }
    ]
  }
}
EOF
        log_success "Grafanaä»ªè¡¨æ¿é…ç½®å·²ç”Ÿæˆ"
    fi
}

# æ„å»ºé•œåƒ
build_images() {
    log_info "æ„å»ºDockeré•œåƒ..."

    # æ„å»ºåç«¯é•œåƒ
    local image_tag="aihub/backend:$(date +%Y%m%d-%H%M%S)"

    docker build -t "$image_tag" .

    if [ $? -eq 0 ]; then
        log_success "åç«¯é•œåƒæ„å»ºæˆåŠŸ: $image_tag"
    else
        log_error "åç«¯é•œåƒæ„å»ºå¤±è´¥"
        exit 1
    fi

    # æ›´æ–°é•œåƒæ ‡ç­¾
    docker tag "$image_tag" aihub/backend:latest

    log_success "é•œåƒæ ‡ç­¾å·²æ›´æ–°: aihub/backend:latest"
}

# å¤‡ä»½æ•°æ®
backup_data() {
    log_info "å¤‡ä»½ç°æœ‰æ•°æ®..."

    local backup_dir="backups/$(date +%Y%m%d-%H%M%S)"
    mkdir -p "$backup_dir"

    # å¤‡ä»½æ•°æ®åº“ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if docker ps -q postgres | grep -q .; then
        log_info "å¤‡ä»½PostgreSQLæ•°æ®..."
        docker exec ai-hub-postgres pg_dump -U postgres ai_hub_prod > "$backup_dir/postgres_backup.sql"
        log_success "PostgreSQLæ•°æ®å·²å¤‡ä»½"
    fi

    # å¤‡ä»½Redisæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if docker ps -q redis | grep -q .; then
        log_info "å¤‡ä»½Redisæ•°æ®..."
        docker exec ai-hub-redis redis-cli BGSAVE
        docker cp ai-hub-redis:/data/dump.rdb "$backup_dir/redis_backup.rdb"
        log_success "Redisæ•°æ®å·²å¤‡ä»½"
    fi

    # å¤‡ä»½é…ç½®æ–‡ä»¶
    log_info "å¤‡ä»½é…ç½®æ–‡ä»¶..."
    cp -r config/ "$backup_dir/"
    cp -r secrets/ "$backup_dir/"
    cp .env.prod "$backup_dir/" 2>/dev/null || true
    cp docker-compose.prod.yml "$backup_dir/" 2>/dev/null || true

    log_success "æ•°æ®å¤‡ä»½å®Œæˆ: $backup_dir"
}

# æ•°æ®åº“è¿ç§»
migrate_database() {
    log_info "æ‰§è¡Œæ•°æ®åº“è¿ç§»..."

    # è¿è¡Œæ•°æ®åº“è¿ç§»
    docker-compose -f docker-compose.prod.yml exec backend alembic upgrade head

    if [ $? -eq 0 ]; then
        log_success "æ•°æ®åº“è¿ç§»å®Œæˆ"
    else
        log_error "æ•°æ®åº“è¿ç§»å¤±è´¥"
        exit 1
    fi
}

# å¥åº·æ£€æŸ¥
health_check() {
    log_info "æ‰§è¡Œå¥åº·æ£€æŸ¥..."

    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    log_info "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
    sleep 30

    # æ£€æŸ¥åç«¯å¥åº·çŠ¶æ€
    max_attempts=10
    attempt=1

    while [ $attempt -le $max_attempts ]; do
        if curl -f http://localhost:8001/health &>/dev/null; then
            log_success "åç«¯æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡"
            break
        else
            log_warning "åç«¯æœåŠ¡å°šæœªå°±ç»ªï¼Œç­‰å¾…10ç§’åé‡è¯• ($attempt/$max_attempts)..."
            sleep 10
            ((attempt++))
        fi
    done

    if [ $attempt -gt $max_attempts ]; then
        log_error "åç«¯æœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥"
        return 1
    fi

    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    if docker-compose -f docker-compose.prod.yml exec backend python -c "
from backend.core.database import get_db
try:
    with get_db() as db:
        db.execute('SELECT 1')
    print('æ•°æ®åº“è¿æ¥æ­£å¸¸')
except Exception as e:
    print(f'æ•°æ®åº“è¿æ¥å¤±è´¥: {e}')
    exit(1)
" &>/dev/null; then
        log_success "æ•°æ®åº“è¿æ¥æ­£å¸¸"
    else
        log_error "æ•°æ®åº“è¿æ¥å¤±è´¥"
        return 1
    fi

    # æ£€æŸ¥Redisè¿æ¥
    if docker-compose -f docker-compose.prod.yml exec backend python -c "
import redis
r = redis.Redis(host='redis', port=6379, password='your_redis_password')
try:
    r.ping()
    print('Redisè¿æ¥æ­£å¸¸')
except Exception as e:
    print(f'Redisè¿æ¥å¤±è´¥: {e}')
    exit(1)
" &>/dev/null; then
        log_success "Redisè¿æ¥æ­£å¸¸"
    else
        log_warning "Redisè¿æ¥æ£€æŸ¥è·³è¿‡ï¼ˆå¯èƒ½æœªé…ç½®å¯†ç ï¼‰"
    fi

    log_success "æ‰€æœ‰å¥åº·æ£€æŸ¥é€šè¿‡"
}

# éƒ¨ç½²æœåŠ¡
deploy_services() {
    log_info "éƒ¨ç½²ç”Ÿäº§ç¯å¢ƒæœåŠ¡..."

    # åœæ­¢ç°æœ‰æœåŠ¡
    log_info "åœæ­¢ç°æœ‰æœåŠ¡..."
    docker-compose -f docker-compose.prod.yml down || true

    # å¯åŠ¨æ–°æœåŠ¡
    log_info "å¯åŠ¨ç”Ÿäº§ç¯å¢ƒæœåŠ¡..."
    docker-compose -f docker-compose.prod.yml up -d

    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    log_info "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
    sleep 60

    # éªŒè¯éƒ¨ç½²
    log_info "éªŒè¯éƒ¨ç½²çŠ¶æ€..."

    # æ£€æŸ¥å®¹å™¨çŠ¶æ€
    local containers=("ai-hub-nginx" "ai-hub-backend" "ai-hub-postgres" "ai-hub-redis")
    all_running=true

    for container in "${containers[@]}"; do
        if ! docker ps -q "$container" | grep -q .; then
            log_warning "å®¹å™¨ $container æœªè¿è¡Œ"
            all_running=false
        else
            log_success "å®¹å™¨ $container è¿è¡Œæ­£å¸¸"
        fi
    done

    if [ "$all_running" = true ]; then
        log_success "æ‰€æœ‰æœåŠ¡éƒ¨ç½²æˆåŠŸ"
    else
        log_error "éƒ¨åˆ†æœåŠ¡éƒ¨ç½²å¤±è´¥"
        return 1
    fi
}

# éªŒè¯éƒ¨ç½²
verify_deployment() {
    log_info "éªŒè¯éƒ¨ç½²ç»“æœ..."

    # è¿è¡Œå¥åº·æ£€æŸ¥
    health_check

    # æµ‹è¯•APIåŠŸèƒ½
    log_info "æµ‹è¯•APIåŠŸèƒ½..."

    if curl -f http://localhost/health &>/dev/null; then
        log_success "APIå¥åº·æ£€æŸ¥ç«¯ç‚¹æ­£å¸¸"
    else
        log_warning "APIå¥åº·æ£€æŸ¥ç«¯ç‚¹å¼‚å¸¸"
    fi

    # æ˜¾ç¤ºæœåŠ¡çŠ¶æ€
    log_info "æœåŠ¡çŠ¶æ€:"
    docker-compose -f docker-compose.prod.yml ps

    # æ˜¾ç¤ºç«¯å£æ˜ å°„
    log_info "ç«¯å£æ˜ å°„:"
    docker-compose -f docker-compose.prod.yml port

    log_success "éƒ¨ç½²éªŒè¯å®Œæˆ"
}

# æ˜¾ç¤ºéƒ¨ç½²ä¿¡æ¯
show_deployment_info() {
    log_info "éƒ¨ç½²ä¿¡æ¯:"
    echo "=========================="
    echo "éƒ¨ç½²ç¯å¢ƒ: $ENVIRONMENT"
    echo "éƒ¨ç½²æ—¶é—´: $(date)"
    echo "Dockeré•œåƒ: aihub/backend:latest"
    echo "=========================="
    echo ""
    echo "æœåŠ¡è®¿é—®åœ°å€:"
    echo "- å‰ç«¯: https://aihub.example.com"
    echo "- API: https://aihub.example.com/api/v1"
    echo "- ç›‘æ§: http://localhost:3000 (Grafana)"
    echo "- æŒ‡æ ‡: http://localhost:9090 (Prometheus)"
    echo ""
    echo "ç®¡ç†å‘½ä»¤:"
    echo "- æŸ¥çœ‹æ—¥å¿—: docker-compose -f docker-compose.prod.yml logs -f [service]"
    echo "- é‡å¯æœåŠ¡: docker-compose -f docker-compose.prod.yml restart [service]"
    echo "- åœæ­¢æœåŠ¡: docker-compose -f docker-compose.prod.yml down"
    echo ""
    echo "é…ç½®æ–‡ä»¶ä½ç½®:"
    echo "- ç¯å¢ƒå˜é‡: .env.prod"
    echo "- Dockeré…ç½®: docker-compose.prod.yml"
    echo "- Nginxé…ç½®: nginx/nginx.conf"
    echo "- ç›‘æ§é…ç½®: monitoring/"
}

# ä¸»å‡½æ•°
main() {
    echo "ğŸš€ AI Hub å¹³å°ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²"
    echo "================================="

    # æ£€æŸ¥å‚æ•°
    if [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
        echo "ç”¨æ³•: $0 [é€‰é¡¹]"
        echo ""
        echo "é€‰é¡¹:"
        echo "  --check-only    ä»…æ£€æŸ¥ç¯å¢ƒå’Œä¾èµ–"
        echo "  --config-only   ä»…ç”Ÿæˆé…ç½®æ–‡ä»¶"
        echo "  --build-only    ä»…æ„å»ºé•œåƒ"
        echo "  --backup-only   ä»…å¤‡ä»½æ•°æ®"
        echo "  --no-health-check è·³è¿‡å¥åº·æ£€æŸ¥"
        echo ""
        echo "ç¯å¢ƒå˜é‡:"
        echo "  ENVIRONMENT   éƒ¨ç½²ç¯å¢ƒ (production|staging|development)"
        echo "  BACKUP_DATA    æ˜¯å¦å¤‡ä»½æ•°æ® (true|false)"
        echo "  SKIP_HEALTH_CHECK æ˜¯å¦è·³è¿‡å¥åº·æ£€æŸ¥ (true|false)"
        exit 0
    fi

    # æ£€æŸ¥ä¾èµ–
    check_dependencies

    # éªŒè¯ç¯å¢ƒ
    validate_environment

    # ç”Ÿæˆé…ç½®
    generate_config

    # æ ¹æ®å‚æ•°æ‰§è¡Œç›¸åº”æ“ä½œ
    if [ "$1" = "--check-only" ]; then
        log_success "ç¯å¢ƒæ£€æŸ¥å®Œæˆ"
        exit 0
    fi

    if [ "$1" = "--config-only" ]; then
        log_success "é…ç½®ç”Ÿæˆå®Œæˆ"
        exit 0
    fi

    # å¤‡ä»½æ•°æ®ï¼ˆé»˜è®¤æ‰§è¡Œï¼‰
    if [ "${BACKUP_DATA:-true}" = "true" ]; then
        backup_data
    fi

    # æ„å»ºé•œåƒ
    if [ "$1" != "--no-build" ] && [ "$1" != "--config-only" ] && [ "$1" != "--backup-only" ]; then
        build_images
    fi

    if [ "$1" = "--build-only" ]; then
        log_success "é•œåƒæ„å»ºå®Œæˆ"
        exit 0
    fi

    if [ "$1" = "--backup-only" ]; then
        log_success "æ•°æ®å¤‡ä»½å®Œæˆ"
        exit 0
    fi

    # æ•°æ®åº“è¿ç§»
    migrate_database

    # éƒ¨ç½²æœåŠ¡
    deploy_services

    # å¥åº·æ£€æŸ¥
    if [ "${SKIP_HEALTH_CHECK:-false}" != "true" ]; then
        health_check
    fi

    # éªŒè¯éƒ¨ç½²
    verify_deployment

    # æ˜¾ç¤ºéƒ¨ç½²ä¿¡æ¯
    show_deployment_info

    log_success "ğŸ‰ AI Hub å¹³å°ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å®Œæˆï¼"
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"